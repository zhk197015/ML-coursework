{"cells":[{"cell_type":"markdown","metadata":{"id":"qs0yamHN-dY0"},"source":["# **CIS 4190/5190 Fall 2023 - Homework 6**\n","\n","**Before starting, you must click on the \"Copy To Drive\" option in the top bar. Go to File --> Save a Copy to Drive. This is the master notebook so <u>you will not be able to save your changes without copying it </u>! Once you click on that, make sure you are working on that version of the notebook so that your work is saved**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10816,"status":"ok","timestamp":1701200744113,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"yz4CPNEHjINs","outputId":"5cc7adbe-2a74-4525-b955-177864b4c34e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting dill\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.7\n"]}],"source":["# Restart the runtime after running this cell everytime you open the notebook\n","#!pip install pandas==1.1.5\n","!pip install dill"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rb-WLp5Z-cdy"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import os\n","import sys\n","import matplotlib.pyplot as plt\n","from numpy.linalg import *\n","np.random.seed(42)  # don't change this line\n","\n","import dill\n","import base64"]},{"cell_type":"markdown","metadata":{"id":"cjjXBdEb-p8K"},"source":["# **PennGrader Setup**\n","\n","First, you'll need to set up the PennGrader, an autograder we are going to use throughout the semester. The PennGrader will automatically grade your answer and provide you with an instant feedback. Unless otherwise stated, you can resubmit up to a reasonable number of attempts (e.g. 100 attemptes per day). **We will only record your latest score in our backend database**.\n","\n","After finishing each homework assignment, you must submit your iPython notebook to gradescope before the homework deadline. Gradescope will then retrive and display your scores from our backend database."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GCTLN4G-nK2"},"outputs":[],"source":["%%capture\n","!pip3 install penngrader --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLnoPRci-sTC"},"outputs":[],"source":["from penngrader.grader import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qu0XYZHO-t8J"},"outputs":[],"source":["#PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO\n","#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n","STUDENT_ID = 58397602        # YOUR PENN-ID GOES HERE AS AN INTEGER#"]},{"cell_type":"markdown","metadata":{"id":"tIDTGGbo-xkf"},"source":["Run the following cell to initialize the autograder. This autograder will let you submit your code directly from this notebook and immidiately get a score.\n","\n","**NOTE:** Remember we store your submissions and check against other student's submissions... so, not that you would, but no cheating."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1701200753749,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"bw_QDnZk-vvI","outputId":"9e110db5-67af-4ed1-ec4b-c8b08581cfde"},"outputs":[{"name":"stdout","output_type":"stream","text":["PennGrader initialized with Student ID: 58397602\n","\n","Make sure this correct or we will not be able to store your grade\n"]}],"source":["grader = PennGrader(homework_id = 'CIS5190_F23_HW6', student_id = STUDENT_ID)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XXAI_M8tyI6"},"outputs":[],"source":["# Serialization code needed by the autograder\n","import inspect, sys\n","from IPython.core.magics.code import extract_symbols\n","\n","def new_getfile(object, _old_getfile=inspect.getfile):\n","    if not inspect.isclass(object):\n","        return _old_getfile(object)\n","\n","    # Lookup by parent module (as in current inspect)\n","    if hasattr(object, '__module__'):\n","        object_ = sys.modules.get(object.__module__)\n","        if hasattr(object_, '__file__'):\n","            return object_.__file__\n","\n","    # If parent module is __main__, lookup by methods (NEW)\n","    for name, member in inspect.getmembers(object):\n","        if inspect.isfunction(member) and object.__qualname__ + '.' + member.__name__ == member.__qualname__:\n","            return inspect.getfile(member)\n","    else:\n","        raise TypeError('Source for {!r} not found'.format(object))\n","inspect.getfile = new_getfile\n","\n","def grader_serialize(obj):\n","    cell_code = \"\".join(inspect.linecache.getlines(new_getfile(obj)))\n","    class_code = extract_symbols(cell_code, obj.__name__)[0][0]\n","    return class_code"]},{"cell_type":"markdown","metadata":{"id":"oQCyLhELJ7LX"},"source":["#### **NOTE 1. Results of sections marked as \"manually graded\" should be submitted along with the written homework solutions.**\n","\n","#### **NOTE 2. If you are running into a `__builtins__' error, it's likely because you're using a function call of the form numpy.ndarray.mean(), like a.mean(). This does not play nice with PennGrader unfortunately. Please use the function call numpy.mean(a) instead.**"]},{"cell_type":"markdown","metadata":{"id":"LcrJaJ73Rk9v"},"source":["#1.NLP Section"]},{"cell_type":"markdown","metadata":{"id":"Yp9rryptRoLR"},"source":["#### Stanford Sentiment Treebank(SST)\n","\n","We'll introduce the [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/index.html) (SST) dataset, and use a Naive Bayes model as a simple baseline. The SST was introduced by [(Socher et al. 2013)](http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf) and it consists of approximately 10,000 sentences from movie reviews. It consists of 11,855 sentences drawn from a corpus of movie reviews (originally from Rotten Tomatoes), each labeled with sentiment on a five-point scale ans is a widely used dataset as a benchmark for text classification.\n","\n","An example of the five-point scale is:\n","```\n","sentence: [A warm , funny , engaging film .]\n","label:    4 (very positive)\n","```\n","\n","**Note:** Unlike most classification datasets, SST is also a _treebank_, which means each sentence is associated with a tree structure that decomposes it into subphrases. So for the example above, we'd also have sentiment labels for `[warm , funny]` and `[engaging film .]` and so on. The tree structure will comes in handy for complex NLP tasks and we will be using it briefly to analyze an example that has negation. The data is distributed as serialized trees in [S-expression](https://en.wikipedia.org/wiki/S-expression) form, like this:\n","```\n","(4 (4 (2 A) (4 (3 (3 warm) (2 ,)) (3 funny))) (3 (2 ,) (3 (4 (4 engaging) (2 film)) (2 .))))\n","```\n","\n","We've downladed the dataset and parse the S-expressions into a dataframe.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10653,"status":"ok","timestamp":1701200764391,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"FByUmOl14eyC","outputId":"23d133e2-1344-4474-b23c-f8c744f1e8fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=c7d282c09337178083357154e19d3e2442509cae075470586219b97f5bc660fe\n","  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"]}],"source":["!pip3 install wget"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wothm2Pot6-Z"},"outputs":[],"source":["from __future__ import division\n","import os, sys, re, json, time, datetime, shutil\n","import itertools, collections\n","from importlib import reload\n","\n","# NLTK, NumPy, and Pandas.\n","import nltk\n","from nltk.tree import Tree\n","import numpy as np\n","from numpy import random as rd\n","import random\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdl0NfUrJHxO"},"outputs":[],"source":["import os\n","import collections\n","import re\n","import time\n","import itertools\n","from collections import defaultdict, Counter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ay1YROpJAZ_i"},"outputs":[],"source":["# Constants for use by other modules.\n","START_TOKEN = u\"<s>\"\n","END_TOKEN   = u\"</s>\"\n","UNK_TOKEN   = u\"<unk>\""]},{"cell_type":"markdown","metadata":{"id":"1ma4E29Xe8Hs"},"source":["#### Required files\n","[train parquet file](https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/train.parquet)\n","\n","[dev parquet file](https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/dev.parquet)\n","\n","[test parquet file](https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/test.parquet)\n","\n","[tokens in training data](https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/train_tokens.txt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1389,"status":"ok","timestamp":1701200767640,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"LumyzFXKpDIa","outputId":"608f7a07-98ec-4113-ae6a-e6043764280a"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-11-28 19:46:06--  https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/train_tokens.txt\n","Resolving www.cis.upenn.edu (www.cis.upenn.edu)... 158.130.69.163, 2607:f470:8:64:5ea5::d\n","Connecting to www.cis.upenn.edu (www.cis.upenn.edu)|158.130.69.163|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 886453 (866K) [text/plain]\n","Saving to: ‘train_tokens.txt’\n","\n","train_tokens.txt    100%[===================>] 865.68K  5.58MB/s    in 0.2s    \n","\n","2023-11-28 19:46:06 (5.58 MB/s) - ‘train_tokens.txt’ saved [886453/886453]\n","\n","--2023-11-28 19:46:06--  https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/train.parquet\n","Resolving www.cis.upenn.edu (www.cis.upenn.edu)... 158.130.69.163, 2607:f470:8:64:5ea5::d\n","Connecting to www.cis.upenn.edu (www.cis.upenn.edu)|158.130.69.163|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2893816 (2.8M)\n","Saving to: ‘train.parquet’\n","\n","train.parquet       100%[===================>]   2.76M  11.4MB/s    in 0.2s    \n","\n","2023-11-28 19:46:07 (11.4 MB/s) - ‘train.parquet’ saved [2893816/2893816]\n","\n","--2023-11-28 19:46:07--  https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/dev.parquet\n","Resolving www.cis.upenn.edu (www.cis.upenn.edu)... 158.130.69.163, 2607:f470:8:64:5ea5::d\n","Connecting to www.cis.upenn.edu (www.cis.upenn.edu)|158.130.69.163|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 317137 (310K)\n","Saving to: ‘dev.parquet’\n","\n","dev.parquet         100%[===================>] 309.70K  --.-KB/s    in 0.1s    \n","\n","2023-11-28 19:46:07 (2.54 MB/s) - ‘dev.parquet’ saved [317137/317137]\n","\n","--2023-11-28 19:46:07--  https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/test.parquet\n","Resolving www.cis.upenn.edu (www.cis.upenn.edu)... 158.130.69.163, 2607:f470:8:64:5ea5::d\n","Connecting to www.cis.upenn.edu (www.cis.upenn.edu)|158.130.69.163|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 850723 (831K)\n","Saving to: ‘test.parquet’\n","\n","test.parquet        100%[===================>] 830.78K  3.76MB/s    in 0.2s    \n","\n","2023-11-28 19:46:08 (3.76 MB/s) - ‘test.parquet’ saved [850723/850723]\n","\n"]}],"source":["!wget  -c  https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/train_tokens.txt\n","!wget  -c  https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/train.parquet\n","!wget  -c  https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/dev.parquet\n","!wget  -c  https://www.cis.upenn.edu/~myatskar/teaching/cis519/a5/test.parquet"]},{"cell_type":"markdown","metadata":{"id":"AG1RbvIgdCuz"},"source":["If the cells above fails to download all the files, rerun a couple of times or download them and add them manually."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0JC3vd0cvfG"},"outputs":[],"source":["train_file = \"train.parquet\"\n","dev_file = \"dev.parquet\"\n","test_file = \"test.parquet\"\n","vocab_file = \"train_tokens.txt\""]},{"cell_type":"markdown","metadata":{"id":"olCRGZcIJuEf"},"source":["Some helper code to download and process data"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"fDhs_mpQAQIt"},"outputs":[],"source":["#@title\n","class SSTDataset(object):\n","\n","    Example_fields = [\"tokens\", \"ids\", \"label\", \"is_root\", \"root_id\"]\n","    Example = collections.namedtuple(\"Example\", Example_fields)\n","\n","\n","    def canonicalize(self, raw_tokens):\n","        wordset=(self.vocab.wordset if self.vocab else None)\n","        return canonicalize_words(raw_tokens, wordset=wordset)\n","\n","    def __init__(self,train_file,dev_file,test_file,vocab_file,V=20000):\n","        self.vocab = None\n","        self.train = pd.read_parquet(train_file)\n","        self.dev = pd.read_parquet(dev_file)\n","        self.test = pd.read_parquet(test_file)\n","        train_words =[]\n","        with open(vocab_file) as f:\n","            train_words = f.readlines()\n","        train_words = [w.strip() for w in train_words]\n","        # # Build vocabulary over training set\n","        self.vocab = Vocabulary(train_words, size=V)\n","        print(\"Train set has {:,} words\".format(self.vocab.size))\n","        self.target_names = [0,1]\n","\n","    def get_filtered_split(self, split='train',is_root = True):\n","        df = getattr(self, split)\n","        if is_root:\n","            df = df[df.is_root]\n","        return df\n","\n","    def as_padded_array(self, split='train', max_len=40, pad_id=0,is_root = True):\n","        df = self.get_filtered_split(split,is_root)\n","        x, ns = pad_np_array(df.ids, max_len=max_len, pad_id=pad_id)\n","        y = np.empty((1,1))\n","        if split != 'test':\n","            y  = np.array(df.label, dtype=np.int32)\n","        return x, ns, y\n","\n","    def as_sparse_bow(self, split='train',is_root = True):\n","        from scipy import sparse\n","        df = self.get_filtered_split(split,is_root)\n","        x = id_lists_to_sparse_bow(df['ids'], self.vocab.size)\n","        if split != 'test':\n","            return x, np.array(df.label, dtype=np.int32)\n","        return x\n","\n","def require_package(package_name):\n","    import pkgutil\n","    import subprocess\n","    import sys\n","    if not pkgutil.find_loader(package_name):\n","        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package_name])\n","\n","def canonicalize_digits(word):\n","    if any([c.isalpha() for c in word]): return word\n","    word = re.sub(\"\\d\", \"DG\", word)\n","    if word.startswith(\"DG\"):\n","        word = word.replace(\",\", \"\") # remove thousands separator\n","    return word\n","\n","def canonicalize_word(word, wordset=None, digits=True):\n","    word = word.lower()\n","    if digits:\n","        if (wordset != None) and (word in wordset): return word\n","        word = canonicalize_digits(word) # try to canonicalize numbers\n","    if (wordset == None) or (word in wordset):\n","        return word\n","    else:\n","        return UNK_TOKEN\n","\n","def canonicalize_words(words, **kw):\n","    return [canonicalize_word(word, **kw) for word in words]\n","\n","\n","def pad_np_array(example_ids, max_len=250, pad_id=0):\n","    arr = np.full([len(example_ids), max_len], pad_id, dtype=np.int32)\n","    ns = np.zeros([len(example_ids)], dtype=np.int32)\n","    for i, ids in enumerate(example_ids):\n","        cpy_len = min(len(ids), max_len)\n","        arr[i,:cpy_len] = ids[:cpy_len]\n","        ns[i] = cpy_len\n","    return arr, ns\n","\n","def id_lists_to_sparse_bow(id_lists, vocab_size):\n","    from scipy import sparse\n","    ii = []  # row indices (example ids)\n","    jj = []  # column indices (token ids)\n","    for row_id, ids in enumerate(id_lists):\n","        ii.extend([row_id]*len(ids))\n","        jj.extend(ids)\n","    x = sparse.csr_matrix((np.ones_like(ii), (ii, jj)),\n","                          shape=[len(id_lists), vocab_size])\n","    return x\n","\n","class Vocabulary(object):\n","\n","    START_TOKEN = START_TOKEN\n","    END_TOKEN   = END_TOKEN\n","    UNK_TOKEN   = UNK_TOKEN\n","\n","    def __init__(self, tokens, size=None,\n","                 progressbar=lambda l:l):\n","        self.unigram_counts = Counter()\n","        self.bigram_counts = defaultdict(lambda: Counter())\n","        prev_word = None\n","        for word in progressbar(tokens):  # Make a single pass through tokens\n","            self.unigram_counts[word] += 1\n","            self.bigram_counts[prev_word][word] += 1\n","            prev_word = word\n","        self.bigram_counts.default_factory = None  # make into a normal dict\n","\n","        # Leave space for \"<s>\", \"</s>\", and \"<unk>\"\n","        top_counts = self.unigram_counts.most_common(None if size is None else (size - 3))\n","        vocab = ([self.START_TOKEN, self.END_TOKEN, self.UNK_TOKEN] +\n","                 [w for w,c in top_counts])\n","\n","        # Assign an id to each word, by frequency\n","        self.id_to_word = dict(enumerate(vocab))\n","        self.word_to_id = {v:k for k,v in self.id_to_word.items()}\n","        self.size = len(self.id_to_word)\n","        if size is not None:\n","            assert(self.size <= size)\n","\n","        # For convenience\n","        self.wordset = set(self.word_to_id.keys())\n","\n","        # Store special IDs\n","        self.START_ID = self.word_to_id[self.START_TOKEN]\n","        self.END_ID = self.word_to_id[self.END_TOKEN]\n","        self.UNK_ID = self.word_to_id[self.UNK_TOKEN]\n","\n","    def words_to_ids(self, words):\n","        return [self.word_to_id.get(w, self.UNK_ID) for w in words]\n","\n","    def ids_to_words(self, ids):\n","        return [self.id_to_word[i] for i in ids]\n","\n","    def ordered_words(self):\n","        \"\"\"Return a list of words, ordered by id.\"\"\"\n","        return self.ids_to_words(range(self.size))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":768,"status":"ok","timestamp":1701200768552,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"CSRZ9eqxt6-b","outputId":"0e26f00b-999d-4dcf-9d75-e99b322efd55"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set has 16,474 words\n"]}],"source":["ds = SSTDataset(train_file,dev_file, test_file,vocab_file,V=20000)"]},{"cell_type":"markdown","metadata":{"id":"kY5JE1DQt6-d"},"source":["A few members of the `SSTDataset()` class that we will be using are:\n","- **`ds.vocab`**: a `vocabulary.Vocabulary` object managing the model vocabulary.\n","- **`ds.{train,dev,test}`**: a Pandas DataFrame containing the _processed_ examples, including all subphrases. `label` is the target label, `is_root` denotes whether this example is a root node (full sentence), and `tokens` are the tokenized words from the original sentence."]},{"cell_type":"markdown","metadata":{"id":"16q8ruRjt6-k"},"source":["Note if you set `root_only=True` the dataframe will return only examples corresponding to whole sentences. If you set `root_only=False` the dataframe will return examples for all phrases."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SXUCz-2YeP0"},"outputs":[],"source":["is_root = False"]},{"cell_type":"markdown","metadata":{"id":"K2EMoXKcUQ1G"},"source":["## 1.1 [Deep Averaging Networks](https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf) [25pts, Autograded]\n","\n","We are going to implement the deep averaging networks\n","\n","![dan](https://miro.medium.com/max/904/1*0LezMYWUk3pXptoMdO5M_Q.png)\n","\n","\n","Vector space models for natural language processing (NLP) represent words using low dimensional vectors called embeddings. To apply vector space\n","models to sentences or documents, one must first select an appropriate composition function, which combines multiple words into a single vector.\n","\n","Composition functions fall into two classes: unordered and syntactic. Unordered functions treat input texts as bags of word embeddings, while syntactic functions take word order and sentence structure\n","into account. Syntactic functions outperform unordered functions on many tasks. However, there is a tradeoff: syntactic functions require more training time and computing resources.\n","\n","The deep averaging network (DAN) is a deep unordered model which that obtains near state-of-the-art accuracies on a variety of sentence and document-level tasks with just minutes of training time on an average laptop computer. It\n","works in three simple steps:\n","1. Take the vector average of the embeddings\n","associated with an input sequence of tokens\n","2. Pass that average through one or more feedforward layers\n","3. Perform (linear) classification on the final\n","layer’s representation\n","\n","Furthermore, DANs, can be effectively trained on data that have high syntactic variance. The model works by magnifying tiny but meaningful differences in the vector average."]},{"cell_type":"markdown","metadata":{"id":"6S7vplWWPya4"},"source":["We are going to use DANs for the same classification problem."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVXHs8JIQEg8"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WU2myqExRR1n"},"outputs":[],"source":["import os\n","import time\n","import glob\n","import numpy as np\n","\n","import sys\n","from argparse import ArgumentParser"]},{"cell_type":"markdown","metadata":{"id":"Q5ulmPzRwr3T"},"source":["### 1.1.1 [Glove Embeddings](https://nlp.stanford.edu/projects/glove/) [TODO: 5pts]\n","We are downloading pretrained glove word vectors that has been trained on Common Crawl data, a snapshot of the whole web.\n","These embeddings serve as excelent initilizations for embeddings our model needs.\n","Downloading glove embeddings (This will take around 10 minutes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":476391,"status":"ok","timestamp":1701201252683,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"nT27aeXBVw01","outputId":"dae763be-312c-4c25-853c-d8d2844bbe19"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-11-28 19:46:16--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n","--2023-11-28 19:46:17--  https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2176768927 (2.0G) [application/zip]\n","Saving to: ‘glove.840B.300d.zip’\n","\n","glove.840B.300d.zip 100%[===================>]   2.03G  5.21MB/s    in 6m 50s  \n","\n","2023-11-28 19:53:07 (5.07 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n","\n","Archive:  glove.840B.300d.zip\n","  inflating: glove.840B.300d.txt     \n","total 7644520\n","drwxr-xr-x 1 root root       4096 Nov 28 19:53 .\n","drwxr-xr-x 1 root root       4096 Nov 28 19:45 ..\n","drwxr-xr-x 1 root root       4096 Nov 22 14:27 sample_data\n","drwxr-xr-x 4 root root       4096 Nov 22 14:24 .config\n","-rw-r--r-- 1 root root     886453 Mar 21  2022 train_tokens.txt\n","-rw-r--r-- 1 root root     850723 Mar 21  2022 test.parquet\n","-rw-r--r-- 1 root root     317137 Mar 21  2022 dev.parquet\n","-rw-r--r-- 1 root root    2893816 Mar 21  2022 train.parquet\n","-rw-r--r-- 1 root root 2176768927 Oct 24  2015 glove.840B.300d.zip\n","-rw-rw-r-- 1 root root 5646236541 Oct 24  2015 glove.840B.300d.txt\n"]}],"source":["#this takes about 10 minutes to run\n","!wget -nc https://nlp.stanford.edu/data/glove.840B.300d.zip\n","!unzip glove.840B.300d.zip\n","!ls -lat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gukyScOlS6Ri"},"outputs":[],"source":["glove_file = \"glove.840B.300d.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1701201253001,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"MpUv8X36MEru","outputId":"e2ebc24d-9119-419a-a137-bc052f6a1127"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set: x = (98794, 40) sparse, ns=(98794,), y = (98794,)\n","Validation set: x = (13142, 40) sparse,ns=(13142,), y = (13142,)\n","Test set:     x = (26052, 40) sparse,ns=(26052,)\n"]}],"source":["train_x, train_ns, train_y = ds.as_padded_array(\"train\",is_root = is_root)\n","dev_x, dev_ns, dev_y = ds.as_padded_array(\"dev\",is_root = is_root)\n","test_x, test_ns,_  = ds.as_padded_array(\"test\",is_root = is_root)\n","\n","print(\"Training set: x = {:s} sparse, ns={:s}, y = {:s}\".format(str(train_x.shape), str(train_ns.shape),\n","                                                str(train_y.shape)))\n","print(\"Validation set: x = {:s} sparse,ns={:s}, y = {:s}\".format(str(dev_x.shape), str(dev_ns.shape),\n","                                                str(dev_y.shape)))\n","print(\"Test set:     x = {:s} sparse,ns={:s}\".format(str(test_x.shape), str(test_ns.shape)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1701201253237,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"qu-xCT7dIfwD","outputId":"cd49b634-56e2-4a55-eb59-588af80ba464"},"outputs":[{"name":"stdout","output_type":"stream","text":[", -0.082752 0.67204 -0.14987 -0.064983 0.056491 0.40228 0.0027747 -0.3311 -0.30691 2.0817 0.031819 0.013643 0.30265 0.0071297 -0.5819 -0.2774 -0.062254 1.1451 -0.24232 0.1235 -0.12243 0.33152 -0.006162 -0.30541 -0.13057 -0.054601 0.037083 -0.070552 0.5893 -0.30385 0.2898 -0.14653 -0.27052 0.37161 0.32031 -0.29125 0.0052483 -0.13212 -0.052736 0.087349 -0.26668 -0.16897 0.015162 -0.0083746 -0.14871 0.23413 -0.20719 -0.091386 0.40075 -0.17223 0.18145 0.37586 -0.28682 0.37289 -0.16185 0.18008 0.3032 -0.13216 0.18352 0.095759 0.094916 0.008289 0.11761 0.34046 0.03677 -0.29077 0.058303 -0.027814 0.082941 0.1862 -0.031494 0.27985 -0.074412 -0.13762 -0.21866 0.18138 0.040855 -0.113 0.24107 0.3657 -0.27525 -0.05684 0.34872 0.011884 0.14517 -0.71395 0.48497 0.14807 0.62287 0.20599 0.58379 -0.13438 0.40207 0.18311 0.28021 -0.42349 -0.25626 0.17715 -0.54095 0.16596 -0.036058 0.08499 -0.64989 0.075549 -0.28831 0.40626 -0.2802 0.094062 0.32406 0.28437 -0.26341 0.11553 0.071918 -0.47215 -0.18366 -0.34709 0.29964 -0.66514 0.002516 -0.42333 0.27512 0.36012 0.16311 0.23964 -0.05923 0.3261 0.20559 0.038677 -0.045816 0.089764 0.43151 -0.15954 0.08532 -0.26572 -0.15001 0.084286 -0.16714 -0.43004 0.060807 0.13121 -0.24112 0.66554 0.4453 -0.18019 -0.13919 0.56252 0.21457 -0.46443 -0.012211 0.029988 -0.051094 -0.20135 0.80788 0.47377 -0.057647 0.46216 0.16084 -0.20954 -0.05452 0.15572 -0.13712 0.12972 -0.011936 -0.003378 -0.13595 -0.080711 0.20065 0.054056 0.046816 0.059539 0.046265 0.17754 -0.31094 0.28119 -0.24355 0.085252 -0.21011 -0.19472 0.0027297 -0.46341 0.14789 -0.31517 -0.065939 0.036106 0.42903 -0.33759 0.16432 0.32568 -0.050392 -0.054297 0.24074 0.41923 0.13012 -0.17167 -0.37808 -0.23089 -0.019477 -0.29291 -0.30824 0.30297 -0.22659 0.081574 -0.18516 -0.21408 0.40616 -0.28974 0.074174 -0.17795 0.28595 -0.039626 -0.2339 -0.36054 -0.067503 -0.091065 0.23438 -0.0041331 0.003232 0.0072134 0.008697 0.21614 0.049904 0.35582 0.13748 0.073361 0.14166 0.2412 -0.013322 0.15613 0.083381 0.088146 -0.019357 0.43795 0.083961 0.45309 -0.50489 -0.10865 -0.2527 -0.18251 0.20441 0.13319 0.1294 0.050594 -0.15612 -0.39543 0.12538 0.24881 -0.1927 -0.31847 -0.12719 0.4341 0.31177 -0.0040946 -0.2094 -0.079961 0.1161 -0.050794 0.015266 -0.2803 -0.12486 0.23587 0.2339 -0.14023 0.028462 0.56923 -0.1649 -0.036429 0.010051 -0.17107 -0.042608 0.044965 -0.4393 -0.26137 0.30088 -0.060772 -0.45312 -0.19076 -0.20288 0.27694 -0.060888 0.11944 0.62206 -0.19343 0.47849 -0.30113 0.059389 0.074901 0.061068 -0.4662 0.40054 -0.19099 -0.14331 0.018267 -0.18643 0.20709 -0.35598 0.05338 -0.050821 -0.1918 -0.37846 -0.06589\n",". 0.012001 0.20751 -0.12578 -0.59325 0.12525 0.15975 0.13748 -0.33157 -0.13694 1.7893 -0.47094 0.70434 0.26673 -0.089961 -0.18168 0.067226 0.053347 1.5595 -0.2541 0.038413 -0.01409 0.056774 0.023434 0.024042 0.31703 0.19025 -0.37505 0.035603 0.1181 0.012032 -0.037566 -0.5046 -0.049261 0.092351 0.11031 -0.073062 0.33994 0.28239 0.13413 0.070128 -0.022099 -0.28103 0.49607 -0.48693 -0.090964 -0.1538 -0.38011 -0.014228 -0.19392 -0.11068 -0.014088 -0.17906 0.24509 -0.16878 -0.15351 -0.13808 0.02151 0.13699 0.0068061 -0.14915 -0.38169 0.12727 0.44007 0.32678 -0.46117 0.068687 0.34747 0.18827 -0.31837 0.4447 -0.2095 -0.26987 0.48945 0.15388 0.05295 -0.049831 0.11207 0.14881 -0.37003 0.30777 -0.33865 0.045149 -0.18987 0.26634 -0.26401 -0.47556 0.68381 -0.30653 0.24606 0.31611 -0.071098 0.030417 0.088119 0.045025 0.20125 -0.21618 -0.36371 -0.25948 -0.42398 -0.14305 -0.10208 0.21498 -0.21924 -0.17935 0.21546 0.13801 0.24504 -0.2559 0.054815 0.21307 0.2564 -0.25673 0.17961 -0.47638 -0.25181 -0.0091498 -0.054362 -0.21007 0.12597 -0.40795 -0.021164 0.20585 0.18925 -0.0051896 -0.51394 0.28862 -0.077748 -0.27676 0.46567 -0.14225 -0.17879 -0.4357 -0.32481 0.15034 -0.058367 0.49652 0.20472 0.019866 0.13326 0.12823 -1.0177 0.29007 0.28995 0.029994 -0.10763 0.28665 -0.24387 0.22905 -0.26249 -0.069269 -0.17889 0.21936 0.15146 0.04567 -0.050497 0.071482 -0.1027 -0.080705 0.30296 0.031302 0.26613 -0.0060951 0.10313 -0.39987 -0.043945 -0.057625 0.08702 -0.098152 0.22835 -0.005211 0.038075 0.01591 -0.20622 0.021853 0.0040426 -0.043063 -0.002294 -0.26097 -0.25802 -0.28158 -0.23118 -0.010404 -0.30102 -0.4042 0.014653 -0.10445 0.30377 -0.20957 0.3119 0.068272 0.1008 0.010423 0.54011 0.29865 0.12653 0.013761 0.21738 -0.39521 0.066633 0.50327 0.14913 -0.11554 0.010042 0.095698 0.16607 -0.18808 0.055019 0.026715 -0.3164 -0.046583 -0.051591 0.023475 -0.11007 0.085642 0.28394 0.040497 0.071986 0.14157 -0.021199 0.44718 0.20088 -0.12964 -0.067183 0.47614 0.13394 -0.17287 -0.37324 -0.17285 0.02683 -0.1316 0.09116 -0.46487 0.1274 -0.090159 -0.10552 0.068006 -0.13381 0.17056 0.089509 -0.23133 -0.27572 0.061534 -0.051646 0.28377 0.25286 -0.24139 -0.19905 0.12049 -0.1011 0.27392 0.27843 0.26449 -0.18292 -0.048961 0.19198 0.17192 0.33659 -0.20184 -0.34305 -0.24553 -0.15399 0.3945 0.22839 -0.25753 -0.25675 -0.37332 -0.23884 -0.048816 0.78323 0.18851 -0.26477 0.096566 0.062658 -0.30668 -0.43334 0.10006 0.21136 0.039459 -0.11077 0.24421 0.60942 -0.46646 0.086385 -0.39702 -0.23363 0.021307 -0.10778 -0.2281 0.50803 0.11567 0.16165 -0.066737 -0.29556 0.022612 -0.28135 0.0635 0.14019 0.13871 -0.36049 -0.035\n","the 0.27204 -0.06203 -0.1884 0.023225 -0.018158 0.0067192 -0.13877 0.17708 0.17709 2.5882 -0.35179 -0.17312 0.43285 -0.10708 0.15006 -0.19982 -0.19093 1.1871 -0.16207 -0.23538 0.003664 -0.19156 -0.085662 0.039199 -0.066449 -0.04209 -0.19122 0.011679 -0.37138 0.21886 0.0011423 0.4319 -0.14205 0.38059 0.30654 0.020167 -0.18316 -0.0065186 -0.0080549 -0.12063 0.027507 0.29839 -0.22896 -0.22882 0.14671 -0.076301 -0.1268 -0.0066651 -0.052795 0.14258 0.1561 0.05551 -0.16149 0.09629 -0.076533 -0.049971 -0.010195 -0.047641 -0.16679 -0.2394 0.0050141 -0.049175 0.013338 0.41923 -0.10104 0.015111 -0.077706 -0.13471 0.119 0.10802 0.21061 -0.051904 0.18527 0.17856 0.041293 -0.014385 -0.082567 -0.035483 -0.076173 -0.045367 0.089281 0.33672 -0.22099 -0.0067275 0.23983 -0.23147 -0.88592 0.091297 -0.012123 0.013233 -0.25799 -0.02972 0.016754 0.01369 0.32377 0.039546 0.042114 -0.088243 0.30318 0.087747 0.16346 -0.40485 -0.043845 -0.040697 0.20936 -0.77795 0.2997 0.2334 0.14891 -0.39037 -0.053086 0.062922 0.065663 -0.13906 0.094193 0.10344 -0.2797 0.28905 -0.32161 0.020687 0.063254 -0.23257 -0.4352 -0.017049 -0.32744 -0.047064 -0.075149 -0.18788 -0.015017 0.029342 -0.3527 -0.044278 -0.13507 -0.11644 -0.1043 0.1392 0.0039199 0.37603 0.067217 -0.37992 -1.1241 -0.057357 -0.16826 0.03941 0.2604 -0.023866 0.17963 0.13553 0.2139 0.052633 -0.25033 -0.11307 0.22234 0.066597 -0.11161 0.062438 -0.27972 0.19878 -0.36262 -1.0006e-05 -0.17262 0.29166 -0.15723 0.054295 0.06101 -0.39165 0.2766 0.057816 0.39709 0.025229 0.24672 -0.08905 0.15683 -0.2096 -0.22196 0.052394 -0.01136 0.050417 -0.14023 -0.042825 -0.031931 -0.21336 -0.20402 -0.23272 0.07449 0.088202 -0.11063 -0.33526 -0.014028 -0.29429 -0.086911 -0.1321 -0.43616 0.20513 0.0079362 0.48505 0.064237 0.14261 -0.43711 0.12783 -0.13111 0.24673 -0.27496 0.15896 0.43314 0.090286 0.24662 0.066463 -0.20099 0.1101 0.03644 0.17359 -0.15689 -0.086328 -0.17316 0.36975 -0.40317 -0.064814 -0.034166 -0.013773 0.062854 -0.17183 -0.12366 -0.034663 -0.22793 -0.23172 0.239 0.27473 0.15332 0.10661 -0.060982 -0.024805 -0.13478 0.17932 -0.37374 -0.02893 -0.11142 -0.08389 -0.055932 0.068039 -0.10783 0.1465 0.094617 -0.084554 0.067429 -0.3291 0.034082 -0.16747 -0.25997 -0.22917 0.020159 -0.02758 0.16136 -0.18538 0.037665 0.57603 0.20684 0.27941 0.16477 -0.018769 0.12062 0.069648 0.059022 -0.23154 0.24095 -0.3471 0.04854 -0.056502 0.41566 -0.43194 0.4823 -0.051759 -0.27285 -0.25893 0.16555 -0.1831 -0.06734 0.42457 0.010346 0.14237 0.25939 0.17123 -0.13821 -0.066846 0.015981 -0.30193 0.043579 -0.043102 0.35025 -0.19681 -0.4281 0.16899 0.22511 -0.28557 -0.1028 -0.018168 0.11407 0.13015 -0.18317 0.1323\n","and -0.18567 0.066008 -0.25209 -0.11725 0.26513 0.064908 0.12291 -0.093979 0.024321 2.4926 -0.017916 -0.071218 -0.24782 -0.26237 -0.2246 -0.21961 -0.12927 1.0867 -0.66072 -0.031617 -0.057328 0.056903 -0.27939 -0.39825 0.14251 -0.085146 -0.14779 0.055067 -0.0028687 -0.20917 -0.070735 0.22577 -0.15881 -0.10395 0.09711 -0.56251 -0.32929 -0.20853 0.0098711 0.049777 0.0014883 0.15884 0.042771 -0.0026956 -0.02462 -0.19213 -0.22556 0.10838 0.090086 -0.13291 0.32559 -0.17038 -0.1099 -0.23986 -0.024289 0.014656 -0.237 0.084828 -0.35982 -0.076746 0.048909 0.11431 -0.21013 0.24765 -0.017531 -0.14028 0.046191 0.22972 0.1175 0.12724 0.012992 0.4587 0.41085 0.039106 0.15713 -0.18376 0.26834 0.056662 0.16844 -0.053788 -0.091892 0.11193 -0.08681 -0.13324 0.15062 -0.31733 -0.22078 0.25038 0.34131 0.36419 -0.089514 -0.22193 0.24471 0.040091 0.47798 -0.029996 0.0019212 0.063511 -0.20417 -0.26478 0.20649 0.015573 -0.27722 -0.18861 -0.10289 -0.49773 0.14986 -0.010877 0.25085 -0.28117 0.18966 -0.065879 0.094753 -0.15338 -0.055071 -0.36747 0.24993 0.096527 0.23538 0.18405 0.052859 0.22967 0.12582 0.15536 -0.17275 0.33946 -0.10049 0.074948 -0.093575 -0.04049 -0.016922 -0.0058039 -0.18108 0.19537 0.45178 0.10965 0.2337 -0.09905 -0.078633 0.21678 -0.71231 -0.099759 0.33333 -0.1646 -0.091688 0.21056 0.023669 0.028922 0.1199 -0.12512 -0.026037 -0.062217 0.55816 0.0050273 -0.30888 0.038611 0.17568 -0.11163 -0.10815 -0.19444 0.29433 0.14519 -0.042878 0.18534 0.018891 -0.61883 0.13352 0.036007 0.33995 0.22109 -0.079328 0.071319 0.17678 0.16378 -0.23142 -0.1434 -0.098122 -0.019286 0.2356 -0.34013 -0.061007 -0.23208 -0.31152 0.10063 -0.15957 0.20183 -0.016345 -0.12303 0.022667 -0.20986 -0.20127 -0.087883 0.064731 0.10195 -0.1786 0.33056 0.21407 -0.32165 -0.17106 0.19407 -0.38618 -0.2148 -0.052254 0.023175 0.47389 0.18612 0.12711 0.20855 -0.10256 -0.12016 -0.40488 0.029695 -0.027419 -0.0085227 -0.11415 0.081134 -0.17228 0.19142 0.026514 0.043789 -0.12399 0.13354 0.10112 0.081682 -0.15085 0.0075806 -0.18971 0.24669 0.22491 0.35553 -0.3277 -0.21821 0.1402 0.28604 0.055226 -0.086544 0.02111 -0.19236 0.074245 0.076782 0.00081666 0.034097 -0.57719 0.10657 0.28134 -0.11964 -0.68281 -0.32893 -0.24442 -0.025847 0.0091273 0.2025 -0.050959 -0.11042 0.010962 0.076773 0.40048 -0.40739 -0.44773 0.31954 -0.036326 -0.012789 -0.17282 0.1476 0.2356 0.080642 -0.36528 -0.0083443 0.6239 -0.24379 0.019917 -0.28803 -0.010494 0.038412 -0.11718 -0.072462 0.16381 0.38488 -0.029783 0.23444 0.4532 0.14815 -0.027021 -0.073181 -0.1147 -0.0054545 0.47796 0.090912 0.094489 -0.36882 -0.59396 -0.097729 0.20072 0.17055 -0.0047356 -0.039709 0.32498 -0.023452 0.12302 0.3312\n","to 0.31924 0.06316 -0.27858 0.2612 0.079248 -0.21462 -0.10495 0.15495 -0.03353 2.4834 -0.50904 0.08749 0.21426 0.22151 -0.25234 -0.097544 -0.1927 1.3606 -0.11592 -0.10383 0.21929 0.11997 -0.11063 0.14212 -0.16643 0.21815 0.0042086 -0.070012 -0.23532 -0.26518 0.031248 0.16669 -0.089777 0.20059 0.31614 -0.5583 0.075735 0.27635 0.12741 -0.18185 -0.12722 0.024686 -0.077233 -0.48998 0.020355 0.0039164 0.1215 0.089723 -0.078975 0.081443 -0.099087 -0.055621 0.10737 -0.0044042 0.48496 0.11717 -0.017329 0.109 -0.35558 0.051084 0.15714 0.17961 -0.29711 0.033645 -0.025792 -0.013931 -0.23 -0.040306 0.22282 -0.013544 0.011554 0.3911 0.26533 -0.31012 0.40539 -0.042975 0.020811 -0.33033 0.19573 -0.037958 0.10274 -0.0013581 -0.44505 0.077886 0.08511 -0.20285 -0.19481 0.056933 0.53105 0.034154 -0.56996 -0.18469 0.093403 0.28044 -0.23349 0.10938 -0.014288 -0.274 0.034196 -0.098479 0.13268 0.19437 0.13463 -0.099059 0.040324 -0.66272 0.3571 0.15429 0.18598 0.087542 0.080538 -0.25121 0.24155 0.1783 0.036011 -0.027677 0.21161 -0.29107 -0.0083456 0.11317 0.31064 -0.10693 -0.27367 -0.039785 0.039881 0.034462 -0.16518 0.16115 0.060826 0.3075 -0.22398 0.14619 -0.2661 0.49732 -0.13996 -0.24287 0.039469 -0.084495 -0.24315 0.070701 -1.0136 -0.21733 -0.36878 -0.24973 0.17472 -0.011592 0.068561 -0.090411 0.21878 -0.2639 0.11904 0.14285 -0.18707 -0.13474 -0.13232 -0.26553 0.22947 -0.018215 0.0067383 -0.1019 0.10053 -0.1127 -0.13295 0.15951 0.14906 -0.095578 0.26992 0.011057 0.056568 0.021386 0.20215 0.00048589 0.5336 -0.22947 0.29275 0.17378 0.25423 -0.10976 0.058816 0.014616 -0.04306 0.10732 -0.028149 -0.19181 0.1025 -0.063892 0.012737 -0.12913 0.015037 0.26562 -0.017049 -0.060716 -0.094919 0.017775 0.13221 0.1683 -0.19323 -0.17612 0.075506 0.18939 0.12508 -0.1988 -0.16017 -0.21092 0.46933 0.044747 0.098349 0.011637 0.22281 -0.010837 -0.04833 -0.47335 -0.36811 -0.13592 -0.15086 0.25416 0.069531 0.14211 -0.26703 -0.1259 0.12076 -0.26117 0.033024 -0.034398 -0.13968 0.13446 -0.16709 0.15002 -0.13724 0.091226 -0.27718 0.020098 0.26919 0.43016 0.094019 -0.085496 -0.25192 -0.11645 -0.039734 0.0046738 0.54178 -0.16636 0.34546 0.098501 0.47819 -0.38428 -0.3238 -0.14822 -0.47817 0.16704 -0.064505 0.11834 -0.3448 0.096891 0.32309 0.41471 0.19463 -0.20891 -0.12223 -0.058298 -0.20268 0.2948 0.043397 0.10112 0.27177 -0.52124 -0.073794 0.044808 0.41388 0.088782 0.62255 -0.072391 0.090129 0.15428 0.023163 -0.13028 0.061762 0.33803 -0.091581 0.21039 0.05108 0.19184 0.10444 0.2138 -0.35091 -0.23702 0.038399 -0.10031 0.18359 0.025178 -0.12977 0.3713 0.18888 -0.0042738 -0.10645 -0.2581 -0.044629 0.082745 0.097801 0.25045\n","of 0.060216 0.21799 -0.04249 -0.38618 -0.15388 0.034635 0.22243 0.21718 0.0068483 2.4375 -0.27418 0.13572 0.31086 -0.063206 0.00038225 -0.18597 -0.19333 1.4447 -0.38541 -0.28549 0.075627 -0.036799 -0.46068 -0.016835 0.19821 -0.092746 0.18954 -0.00032648 -0.17081 0.50359 0.46256 0.26901 -0.12256 0.24713 0.069305 -0.20777 -0.4456 0.30223 -0.0098344 0.32772 0.11038 0.41271 -0.15854 -0.056983 0.38918 -0.21158 -0.13307 0.40406 0.1749 0.053949 0.10984 -0.18476 -0.054014 0.040112 -0.10175 0.12662 0.069709 -0.24071 -0.20995 -0.051381 0.28219 0.18598 -0.5018 0.27572 -0.18497 -0.18399 0.15696 -0.038444 -0.52238 0.22753 0.048672 -0.078837 0.065448 0.18399 0.40211 -0.12745 -0.12302 0.31072 0.099588 0.036047 -0.25946 0.36128 0.12748 -0.18667 0.16502 -0.3912 -0.67549 0.11291 0.040743 0.034973 -0.04091 -0.039791 -0.40544 -0.015867 0.10239 0.046868 -0.082776 0.015132 -0.14899 -0.25125 0.25244 -0.11851 -0.34127 0.016516 0.30405 -0.541 0.305 0.39065 0.42362 -0.41721 -0.054247 -0.26014 -0.14048 -0.14166 -0.02105 0.050822 -0.078053 0.45922 0.17598 -0.0157 0.09118 0.034263 -0.49995 0.028574 0.12068 0.19781 -0.013025 -0.22418 0.12503 0.14653 -0.23085 0.21987 -0.059321 -0.088169 -0.1252 0.0075112 -0.22421 0.6214 0.2009 -0.02899 -0.65073 0.0053506 -0.12073 0.20988 -0.1684 0.041826 0.054582 0.35247 0.2006 0.031903 -0.053307 -0.44009 0.22495 -0.30616 -0.32855 -0.015779 -0.13913 0.34309 -0.13569 -0.22276 0.14295 0.05501 -0.10616 0.23597 -0.20701 -0.30963 0.13528 -0.16144 0.29108 0.12301 0.2365 -0.26153 0.31022 0.20612 -0.19885 0.10971 -0.0018054 0.14621 0.15177 -0.4468 0.0067433 -0.028784 0.13821 -0.16566 -0.45517 0.016623 0.10703 -0.48399 0.040033 0.049625 -0.26454 -0.1468 0.13651 0.15261 0.067522 0.50405 -0.18848 0.15256 -0.26997 0.055578 0.047077 -0.17848 -0.33567 -0.03148 0.19107 0.18818 0.18778 0.18313 -0.364 -0.0054127 -0.15763 0.16386 -0.084828 -0.19838 -0.40454 0.41031 -0.41393 0.029771 0.10544 -0.11295 -0.068076 -0.22372 -0.19084 -0.080269 -0.38345 0.064712 0.23111 0.21408 0.28038 0.14221 -0.20696 0.015874 -0.14112 0.089859 -0.21533 -0.020105 0.22703 0.083425 -0.2958 0.018036 0.19885 0.17794 0.13688 -0.10302 0.029651 0.051271 -0.14787 -0.41824 0.019828 -0.26385 -0.074654 -0.015718 0.48094 0.12492 -0.11409 0.58127 0.095836 -0.095912 -0.057435 0.13883 0.10307 0.081362 -0.4669 0.50705 0.021685 -0.071623 -0.063827 -0.11154 0.61792 -0.56329 0.023565 0.18041 -0.2578 -0.50956 0.14737 -0.033317 -0.037053 0.24062 0.12641 -0.027091 0.4039 -0.02836 -0.022235 -0.11493 -0.2285 -0.05746 0.2952 -0.21914 -0.13307 -0.23647 -0.42484 0.11606 0.0048131 -0.39629 -0.26823 0.3292 -0.17597 0.11709 -0.16692 -0.094085\n","a 0.043798 0.024779 -0.20937 0.49745 0.36019 -0.37503 -0.052078 -0.60555 0.036744 2.2085 -0.23389 -0.06836 -0.22355 -0.053989 -0.15198 -0.17319 0.053355 1.6485 -0.047991 -0.085311 -0.15712 -0.64425 -0.39819 0.278 0.15364 0.031678 0.055414 0.015939 0.31851 -0.058979 0.038584 0.1077 0.1041 -0.077346 0.37396 -0.21482 0.3832 -0.27737 -0.18352 -0.83838 0.34124 0.58164 0.18543 -0.31028 0.17666 -0.069421 -0.34422 -0.13665 -0.10823 0.23637 -0.32923 0.61348 0.1972 0.087123 0.10785 0.3073 0.13757 0.30809 0.24331 -0.29422 -0.0098214 0.55675 -0.04888 0.099468 0.30543 -0.37597 -0.19525 0.046246 -0.036675 0.34023 0.14905 0.0978 -0.26664 0.056834 -0.043201 -0.23338 0.13111 -0.35742 -0.3607 0.30997 -0.19727 -0.1432 -0.16747 0.00042435 -0.1512 0.067562 -0.38644 0.025349 0.24918 -0.23955 -0.15615 0.49868 0.0082758 -0.1912 -0.14906 0.48757 -0.015281 0.010196 0.37642 -0.01946 -0.27835 0.16355 -0.24127 -0.21405 -0.21562 -0.79697 0.34321 0.093209 0.073977 -0.27147 0.20539 0.15061 0.020734 0.11267 0.028714 0.2967 -0.21267 0.43214 0.12788 0.29249 0.19056 -0.29113 -0.11382 -0.038242 -0.2029 0.18301 -0.16661 -0.27116 0.0012685 0.071704 -0.18583 0.08985 -0.039895 0.39479 0.0053211 -0.00061548 -0.27082 -0.089782 -0.2879 -0.14865 -1.3746 0.16515 0.20598 0.15252 0.034723 -0.38531 -0.094574 -0.19871 0.50239 -0.28702 -0.088727 0.056881 0.13634 0.19034 -0.19353 0.40506 -0.19317 0.22908 0.10055 -0.26895 -0.034727 -0.08401 0.057806 0.011076 -0.043349 -0.26917 -0.19333 0.22181 0.26123 -0.11761 0.10092 -0.15078 0.47153 0.11253 -0.26749 -0.038785 -0.03652 -0.089248 -0.24427 -0.041381 -0.021785 -0.35738 -0.063409 -0.53983 -0.010112 0.00041238 -0.097049 0.42628 -0.21349 -0.41055 -0.2494 -0.033571 -0.4954 0.15557 0.19882 0.10498 -0.24372 0.11429 -0.039279 -0.36258 0.10318 0.129 -0.41785 -0.041607 0.33522 0.073186 0.13362 0.010812 0.052645 0.18801 -0.30185 0.20333 -0.32258 -0.24673 0.21124 0.79132 -0.41539 0.3622 0.099852 -0.035378 -0.0419 -0.13851 -0.063255 0.13635 0.090863 -0.3994 0.099062 0.3221 -0.12256 -0.085906 -0.10218 0.2635 -0.18689 -0.1856 -0.43923 -0.325 -0.1991 0.17831 -0.27283 0.33473 0.082382 0.12825 0.39275 -0.034929 0.16148 -0.026713 0.40129 -0.39503 -0.064823 -0.08982 -0.066592 -0.34537 0.046283 0.36837 -0.024573 0.32213 0.30641 -0.28112 0.0066449 0.087743 -0.03417 0.60373 0.4212 -0.073349 0.26682 -0.1586 0.23765 -0.0062604 0.15236 -0.23409 0.31634 -0.08786 -0.15747 -0.24955 -0.18766 -0.096743 -0.27994 -0.24334 0.32643 0.29906 0.42763 0.22266 -0.17464 -0.019916 -0.31206 -0.34009 -0.14993 -0.28818 0.1475 -0.040503 -0.10347 0.0033634 0.2176 -0.20409 0.092415 0.080421 -0.061246 -0.30099 -0.14584 0.28188\n","in 0.089187 0.25792 0.26282 -0.029365 0.47187 -0.10389 -0.10013 0.08123 0.20883 2.5726 -0.67854 0.036121 0.13085 0.0012462 0.14769 0.26926 0.37144 1.3501 -0.11326 -0.23036 -0.26575 -0.18077 0.092455 -0.16215 0.15003 -0.34547 0.072295 0.40659 0.010021 -0.0079257 -0.11435 0.017008 -0.29789 0.19079 0.37112 -0.26588 0.16212 0.065469 -0.31781 -0.03226 0.081969 0.3445 -0.17362 -0.35745 0.054487 0.39941 0.13699 -0.022066 0.11025 -0.41898 0.1276 -0.095869 -0.17944 -0.17443 0.27302 -0.19464 0.26747 -0.28241 0.1638 -0.11518 0.013196 -0.10616 -0.36093 0.023634 0.13464 0.021652 -0.27094 -0.018737 0.10017 0.36071 -0.093951 0.47634 0.12874 0.0011868 0.1377 -0.14034 -0.1887 -0.16405 -0.15349 0.32347 -0.17616 0.3523 -0.023531 -0.19121 -0.054809 -0.099521 -0.30056 0.36632 -0.21509 0.074123 -0.20267 0.1286 -0.38111 -0.025482 0.45103 0.088633 0.36288 -0.23406 -0.086024 -0.50604 0.034242 0.43998 -0.083023 -0.11969 0.68686 -0.34115 0.21228 0.40039 0.26367 -0.37144 0.16206 -0.42854 0.078658 -0.2905 0.21727 -0.27484 0.35887 0.27055 -0.11326 -0.14848 -0.0050659 -0.076862 0.078621 -0.24922 0.42026 -0.069698 0.071595 0.0071665 0.27473 -0.15664 0.25713 -0.058461 -0.29733 -0.090996 0.5246 0.14889 -0.20883 -0.13004 -0.20022 0.4503 -0.34654 -0.26007 0.35247 -0.34757 0.033738 0.19907 -0.32912 -0.084689 0.65319 0.20954 0.079274 0.1086 0.0026466 -0.12843 -0.22811 0.051501 -0.27429 0.14505 -0.1843 -0.34825 -0.11701 0.34034 0.075848 0.08239 -0.39188 -0.022312 -0.080373 0.14477 0.29701 -0.10523 0.092893 0.029813 -0.11761 0.16308 0.098382 0.46152 -0.162 -0.2456 0.20293 -0.11344 0.057902 -0.19528 -0.20141 -0.22874 -0.014101 0.2637 -0.10028 -0.051896 0.18859 -0.17767 -0.11556 0.121 0.17303 0.11773 0.034837 0.28485 -0.30447 0.061024 -0.26442 -0.081135 -0.044524 -0.036931 -0.15217 0.29175 0.44926 -0.28875 0.33193 -0.01242 -0.18805 -0.19832 -0.19736 0.26893 0.11106 -0.67383 -0.1518 -0.16615 -0.16563 0.0093671 -0.15945 -0.33468 0.22038 -0.16724 -0.1535 -0.61782 -0.17258 0.088928 0.019411 0.18296 0.32967 -0.0024906 -0.09208 0.514 0.0042484 -0.084377 -0.71448 -0.22148 -0.04835 0.043761 -0.29376 -0.22287 0.18001 0.072197 0.46499 0.056466 0.40844 -0.23641 -0.038946 0.087363 -0.21901 -0.3231 -0.19989 -0.3128 -0.067656 -0.22596 0.090926 0.28365 0.31462 0.46082 -0.024871 -0.14605 0.30454 0.17704 -0.011311 0.26807 -0.032461 -0.16644 -0.15313 -0.20426 -0.3082 -0.2459 0.085848 -0.11767 -0.063056 -0.18133 -0.18629 -0.17694 0.29618 0.35987 0.0020102 0.38616 0.36712 -0.055112 -0.34733 -0.072678 -0.051119 -0.29069 0.053598 0.019587 0.16808 -0.27456 -0.097179 -0.054541 0.19229 -0.48128 -0.20304 0.19368 -0.32546 0.14421 -0.169 0.26501\n","\" -0.075242 0.57337 -0.31908 -0.18484 0.88867 -0.27381 0.077588 0.13905 -0.47746 1.4442 -0.56159 0.085829 0.27504 0.1567 0.088067 0.038404 0.13146 0.80903 -0.16476 -0.26437 -0.25213 -0.10082 0.23976 -0.0017618 -0.14791 -0.042768 0.087014 0.4747 -0.0018207 -0.38313 -0.18743 -0.17626 -0.31186 0.11831 0.23195 -0.19336 -0.54827 -0.11649 -0.23389 -0.04854 -0.31656 0.04927 0.0074875 -0.3366 0.39277 -0.25234 -0.24983 0.19855 -0.038369 -0.13467 -0.11403 0.37989 -0.16665 -0.090585 0.22177 0.28434 0.25214 -0.03522 -0.0362 0.092851 -0.1177 -0.1239 0.75229 -0.33378 0.27406 -0.14008 0.12932 -0.081124 -0.23386 0.53654 0.45947 -0.14284 0.080147 0.12924 -0.24142 -0.50243 -0.16263 0.22523 0.528 0.089438 0.010835 -0.15715 -0.49085 -0.30451 -0.06281 -0.033262 -0.34762 -0.61321 0.12422 0.52602 -0.14759 -0.29829 -0.28189 -0.075447 -0.52833 0.20302 -0.36833 -0.095067 0.49005 -0.28781 -0.15406 0.2827 -0.085221 -0.24289 -0.22717 0.71889 -0.32832 0.1002 0.20946 0.59244 -0.41214 0.62329 -0.026238 -0.17192 0.49179 -0.0016847 -0.11607 -0.24131 0.11644 -0.1921 0.03934 -0.084155 -0.0996 0.022975 -0.31975 -0.050044 0.52722 0.2252 0.016595 0.20643 -0.0098633 0.31594 -0.078281 0.12947 -0.062864 0.52739 -0.09028 0.14762 0.043752 0.41388 -1.2517 0.16028 0.029431 0.37164 -0.14389 -0.090422 0.33523 0.65587 0.029611 -0.31848 0.15365 0.080007 -0.30963 -0.082044 0.25966 0.070255 -0.56391 -0.70405 -0.16871 0.025228 -0.31917 0.095542 0.03875 -0.27151 -0.45413 -0.27367 0.15582 -0.23491 0.017226 -0.12817 0.19779 -0.070536 -0.46543 -0.30177 0.126 0.28083 0.27455 -0.097111 -0.097692 -0.49537 -0.34073 -0.22939 -0.14542 0.036665 -0.71022 0.3501 -0.23481 0.73786 -0.1357 -0.15819 -0.25091 0.1612 -0.17855 0.19617 0.13535 0.29201 -0.33659 -0.34374 0.022833 0.72946 -0.14079 -0.23412 -0.23124 0.043603 -0.14916 -0.13349 0.26499 -0.072018 0.26515 -0.11531 -0.049195 -0.3157 0.16259 -0.21417 0.26391 0.19793 -0.14555 0.1195 -0.6928 -0.50451 0.21449 0.49722 -0.15937 0.07369 0.28543 -0.16188 0.043208 0.089521 -0.061378 0.005429 0.23594 -0.16455 0.6693 -0.68702 -0.02823 0.30058 -0.053056 -0.35263 -0.21279 0.2776 -0.067762 0.045954 0.23585 -0.18751 0.13449 -0.10923 -0.010326 -0.3995 -0.44222 0.0080668 0.094805 -0.10209 -0.17181 -0.15658 -0.12305 0.61632 0.050099 0.018423 -0.204 0.090514 0.19061 0.022614 0.28797 0.14858 0.18576 -0.025255 -0.061938 -0.20647 0.43831 -0.16193 0.013259 -0.40052 -0.20146 -0.42659 0.38983 -0.084942 0.13971 0.011352 0.025489 0.25282 -0.10832 -0.081995 0.29953 -0.22407 -0.11489 -0.37855 -0.52748 -0.17067 0.16029 0.29872 -0.035604 -0.022669 0.42531 0.063414 0.36213 -0.2128 -0.22615 0.328 -0.10934 -0.37948\n",": 0.008746 0.33214 -0.29175 -0.15119 -0.41842 -0.23931 -0.23458 -0.055618 -0.09896 0.75175 -0.66615 -0.10734 0.021663 -0.12194 0.022265 0.029731 0.036949 1.3326 -0.10886 -0.22681 -0.28436 0.021524 0.22749 -0.093169 -0.11529 0.51138 0.13868 -0.10885 -0.11482 -0.0074179 0.16234 0.0082633 -0.0023698 -0.39662 0.29591 0.22499 -0.46529 0.40232 0.027284 0.14321 0.034624 0.36936 -0.37351 0.22866 -0.29724 0.28951 -0.44012 0.47265 -0.070029 0.54446 0.30543 0.28181 0.063914 -0.30986 -0.40254 -0.032463 -0.39762 0.45387 0.075187 0.068059 0.12686 0.056289 0.29042 0.2362 0.34559 -0.14253 -0.016066 -0.058892 0.22277 0.31318 -0.37625 -0.044296 -0.017026 0.14938 0.87661 0.30364 -0.57488 -0.075509 -0.14493 0.16592 -0.67818 0.45022 -0.23441 -0.077216 0.32643 -0.1757 -0.0067939 -0.51045 0.56891 0.16143 0.18519 0.037305 -0.4579 -0.12869 0.19132 -0.38693 -0.1352 0.050239 0.36475 -0.061642 -0.181 -0.19424 0.46758 -0.25859 0.00027713 1.8061 -0.031111 -0.253 -0.043878 0.33484 0.21194 -0.16946 -0.012677 0.10138 -0.067128 0.2808 0.16923 -0.30368 -0.36514 0.18905 -0.36382 0.25917 0.18678 -0.054908 -0.068399 -0.083712 0.56264 -0.058912 -0.11257 -0.47151 0.62617 0.16101 0.17465 0.29054 -0.17968 0.17995 -0.28868 0.14772 -0.15869 0.12875 -0.050562 0.12813 0.018328 0.087067 -0.42093 0.26649 0.033762 0.46031 0.091036 -0.23591 0.37056 0.061394 -0.1232 -0.3872 0.31078 -0.40397 0.21185 0.14069 -0.32281 0.052793 -0.34045 -0.75221 -0.063703 0.094202 -0.45663 -0.53987 0.48825 -0.18757 -0.19803 0.40647 -0.24817 0.22975 0.21493 -0.48105 0.20716 0.32023 0.63723 -0.069866 0.3692 -0.15806 0.15572 0.36047 -0.010431 -0.27427 -0.087574 -0.37989 -0.1767 0.13558 0.056266 0.10345 -0.40615 0.11801 -0.32919 0.14333 -0.30102 -0.10898 -0.25298 0.33375 0.27642 0.71642 -0.091013 -0.002913 -0.19669 -0.39123 -0.056526 -0.1143 -0.28571 0.17814 -0.038271 -0.19628 -0.0057383 -0.68218 0.55404 -0.31276 -0.11263 -0.16157 -0.40151 0.40366 -0.21163 0.13927 0.32245 0.65676 0.039262 0.1051 -0.40708 -0.061696 0.30114 0.14276 0.24082 -0.29747 0.047918 0.3043 -0.15456 -0.27875 -0.39602 0.26501 -0.19017 0.054386 0.31772 0.44834 0.18064 -0.27069 0.15007 -0.037164 0.35867 0.25197 -0.42951 -0.080519 0.18769 0.35934 -0.12622 -0.034525 -0.44941 -0.27189 0.1923 0.3202 0.085719 -0.31613 0.12747 0.41687 -0.033986 0.16322 0.093101 0.012885 -0.13576 -0.50731 0.34072 0.01102 0.33894 0.043664 -0.22551 0.067386 -0.0061831 -0.10494 0.059349 0.43297 0.55025 0.30155 -0.1616 0.18268 -0.27236 -0.027163 0.61137 0.0027296 0.13913 0.051779 -0.19778 -0.03439 -0.088886 -0.096511 0.33936 -0.041628 -0.5592 0.22176 -0.41515 0.70059 -0.21371 -0.28677 -0.22663 -0.05087\n"]}],"source":["#look at the format of the file\n","!head glove.840B.300d.txt"]},{"cell_type":"markdown","metadata":{"id":"JFe9SkOcYugK"},"source":["#### Get Glove embeddings\n","In this section we want to populate the `glove` dictionary with a mapping of word to the embedding. Remember: the embedding should be an `np.array` of type `np.float` The glove dictionary should only have words that are present in the train vocabulary.\n","\n","\n","Hint:\n","\n","\n","For getting the word and corresponding embedding from the glove file, remember refer to the above structure of the word to embedding mapping."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RNiORwiYTzi"},"outputs":[],"source":["#takes about 1 minute to read through the whole file and find the words we need.\n","def get_glove_mapping(vocab, file):\n","    \"\"\"\n","    Gets the mapping of words from the vocabulary to pretrained embeddings\n","\n","    INPUT:\n","    vocab       - set of vocabulary words\n","    file        - file with pretrained embeddings\n","\n","    OUTPUT:\n","    glove_map   - mapping of words in the vocabulary to the pretrained embedding\n","\n","    \"\"\"\n","\n","    glove_map = {}\n","    with open(file,'rb') as fi:\n","        for l in fi:\n","            try:\n","              l= l.decode('utf-8')\n","              values=l.split()\n","              word=values[0]\n","              embedding=np.array(values[1:],dtype=np.float)\n","\n","              if word in vocab:\n","                glove_map[word]=embedding\n","\n","            except:\n","                #some lines have urls, we don't need them.\n","                pass\n","    return glove_map"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180558,"status":"ok","timestamp":1701201433933,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"kYettRoymWTz","outputId":"6b0d3395-e21b-4ba6-c887-be23e66ded6d"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-23-ef3947ee1240>:22: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  embedding=np.array(values[1:],dtype=np.float)\n"]}],"source":["vocab_set = set(ds.vocab.ordered_words())\n","glove_map = get_glove_mapping(vocab_set,glove_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2K5Mm5a2bpda"},"outputs":[],"source":["def test_glove_embedding(glove_map):\n","    assert(len(glove_map.keys()) == 15505)\n","    assert(\"November\" not in glove_map.keys())\n","\n","test_glove_embedding(glove_map)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":562,"status":"ok","timestamp":1701201434494,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"nGPjrf8rd__p","outputId":"272fdab8-9db0-47aa-9d9b-39f5953a2ae6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 2/2 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_glove_embedding', answer = list(glove_map.keys()))"]},{"cell_type":"markdown","metadata":{"id":"HoZuTVB9mcZb"},"source":["#### Dimensions required for the weight matrix\n","\n","Fill in the dimensions required for weight matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djhLc9X_Z2E0"},"outputs":[],"source":["d_out = len(ds.target_names)  #number of outputs\n","n_embed = ds.vocab.size #size of the dictionary of embeddings\n","d_embed = 300 # the size of each embedding vector\n","dims =(d_out,n_embed,d_embed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qr6jSgYPdJeM"},"outputs":[],"source":["def test_dimensions(dims):\n","    d_out,n_embed,d_embed = dims\n","    assert(n_embed == 16474)\n","    assert(d_out == 2)\n","    assert(d_embed == 300)\n","\n","test_dimensions(dims)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1701201434892,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"K3g0z7Y7e0MA","outputId":"a8e21be1-0e7d-4104-9650-7596ae86cea7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 1/1 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_dimensions', answer = dims)"]},{"cell_type":"markdown","metadata":{"id":"ct2rwpFxlytq"},"source":["#### Initializing the weight matrix\n","\n","Create a weight_matrix for the parameters to be learnt. Initialize the weight matrix for a particular id with the glove embedding for the same id. If you do not find a particular word, initialize the weight matrix with `np.random.normal`\n","\n","Hint: `ds.vocab.ordered_words()` can give you the mapping of id to words. `glove` has the embeddings you need."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMIZjt4HYuJB"},"outputs":[],"source":["def get_weight_matrix(n_embed, d_embed, glove_map):\n","    \"\"\"\n","    Initialize the weight matrix\n","\n","    INPUT:\n","    n_embed         - size of the dictionary of embeddings\n","    d_embed         - the size of each embedding vector\n","\n","    OUTPUT:\n","    weights_matrix  - matrix of mapping from word id to embedding\n","\n","    \"\"\"\n","    #### STUDENT CODE HERE ####\n","    weights_matrix = np.random.normal(size=(n_embed, d_embed))\n","\n","    for id, word in enumerate(ds.vocab.ordered_words()):\n","        if word in glove_map:\n","            weights_matrix[id] = glove_map[word]\n","\n","    #### STUDENT CODE ENDS HERE ####\n","    return weights_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rotHEiIqm2sV"},"outputs":[],"source":["weights_matrix = get_weight_matrix(n_embed, d_embed, glove_map)\n","weight_data = (weights_matrix.shape, weights_matrix[:155])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-Na6gvrdoMN"},"outputs":[],"source":["def test_weight_matrix(weight_data):\n","    mat1 = [-0.18994 ,  0.11016 , -0.46874 ,  0.24375 ,  0.18241 ,  0.2649  ,\n","       -0.025122, -0.58228 , -0.23545 ,  0.20763 ]\n","    shape = (16474, 300)\n","    for i in range(0,10):\n","        if abs(mat1[i] - weight_data[1][150][200+i])>= 0.002:\n","            assert(mat1[i] != weight_data[1][150][200+i])\n","        if shape != weight_data[0]:\n","            assert(shape != weight_data[0])\n","\n","test_weight_matrix(weight_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":660,"status":"ok","timestamp":1701201435767,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"2NHXsYBHgxya","outputId":"bad6df5d-beeb-4909-e16f-2fd1c99880e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 2/2 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_weight_matrix', answer = weight_data)"]},{"cell_type":"markdown","metadata":{"id":"Z6rGLI6jm-0g"},"source":["#### Creating Embedding Layer\n","Use the weight matrix to create the embedding layer by using `nn.Embedding`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4XGB1pAabQAf"},"outputs":[],"source":["def create_emb_layer(weights_matrix, non_trainable=False):\n","    \"\"\"\n","    Create the embedding layer\n","\n","    INPUT:\n","    weights_matrix  - matrix of mapping from word id to embedding\n","    non_trainable   - Flag for whether the weight matrix should be trained.\n","                      If it is set to True, don't update the gradients\n","\n","    OUTPUT:\n","    emb_layer       - embedding layer\n","\n","    \"\"\"\n","    #### STUDENT CODE HERE ####\n","    num_embed, embed_dim = weights_matrix.shape\n","\n","    emb_layer = nn.Embedding(num_embed, embed_dim)\n","\n","\n","    emb_layer.weight.data.copy_(torch.tensor(weights_matrix))\n","\n","    if non_trainable:\n","        # If non_trainable is set to True, don't update the gradients\n","         emb_layer.weight.requires_grad = False\n","    #### STUDENT CODE ENDS HERE ####\n","\n","    return emb_layer"]},{"cell_type":"markdown","metadata":{"id":"FI5HX8dGNQyR"},"source":["#### Defining the Dataloader"]},{"cell_type":"markdown","metadata":{"id":"v2Z4YahqYBBw"},"source":["For the ease of batch processing, we are defining the following to use the functionality of the Dataloader in Pytorch.\n","\n","Note: The process of creating a mask for the word dropout."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOubHTzb8CS2"},"outputs":[],"source":["class SSTpytorchDataset(Dataset):\n","    def __init__(self, sst_ds, word_dropout = 0.3, split='train'):\n","        super(SSTpytorchDataset, self).__init__()\n","        assert split in ['train', 'test', 'dev'], \"Error!\"\n","        self.ds = sst_ds\n","        self.split = split\n","        self.word_dropout = word_dropout\n","        self.data_x, self.data_ns, self.data_y = self.ds.as_padded_array(split,is_root =is_root)\n","        self.mask = np.zeros_like(self.data_x)\n","\n","    def __len__(self):\n","        return self.data_x.shape[0]\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        y = 2\n","        if self.split != 'test':\n","            y = self.data_y[idx]\n","\n","        #Returning the mask for the dataloader\n","\n","        mask = np.zeros(len(self.data_x[idx]))\n","        sentl = self.data_ns[idx]\n","        total_dropped = 0\n","        for j in range(0,sentl):\n","            mask[j] = 1\n","            if self.split == 'train':\n","                rv = random.random()\n","                if rv  < self.word_dropout:\n","                    mask[j] = 0\n","                    total_dropped+=1\n","        if total_dropped >= sentl:\n","            mask[0] = 1\n","        for i in range(sentl,len(self.data_x[idx])):\n","            mask[i] = 0\n","        self.mask[idx] = mask\n","        return self.data_x[idx], self.data_ns[idx], self.mask[idx], y\n"]},{"cell_type":"markdown","metadata":{"id":"uKlnbGShNCDV"},"source":["### 1.1.2 Training [TODO: 20 pts]"]},{"cell_type":"markdown","metadata":{"id":"QnSMLJcrsYC0"},"source":["####  Masked Averaging\n","\n","In this section, you will need to compute the average word embedding of tokens in the input. One complication is that sentences come in different lengths, and we will need to keep track of this to correctly average.\n","\n","When a sentence is input into our network, it is mapped to list of token ids, up to some maximum length. We construct a matrix, M, where each row corresponds to a sentence, and entries correspond to integers representing tokens. Some sentences are, of course, shorter than this maximum length. For these sentences, we fill in the remaining elements of M with a pad index, up to the max length. This is a special pad index indicating we are beyond the end of a sentence. The dataloader takes care of this for you. When averaging, we need to ignore these elements.\n","\n","Irrespective of if a token is pad or a real token, the first step is to look up an embedding for the index in our embedding table (the first line of the forward method). At this point we will have retrieved some vectors that correspond to the pad tokens as well. We need to ignore these, and only average vectors that correspond to non-pad symbols.\n","\n","To help do so, often NLP applications will introduce a mask as part of the input. The mask is a binary vector for every sentence, where each position encodes whether the token is really from the sentence, or instead should be ignored. The shape of the mask is batch_size by maximum_length. Again, the dataloader has taken care of this for you. Your job will be to use this mask to ignore the embeddings components we don't want to average over.\n","\n","You have to perform the following steps:\n","\n","1. Change the view of the mask so it extends to the embeddings size. It started batch_size by maximum_length, but we need it to be batch_size by max_length by embed_dimension. The expand function will help.\n","2. Pointwise multiply the expanded mask with the embeddings, to eliminate the tokens that aren't in the mask, and sum the rest (this is the `numerator` of our average). Remeber the mask is a binary vector, so the zeros correspond to elements we don't want in our average. The output of this sum should be batch_size by embed_dimension.\n","4. Calculate the number of words in each sentence (this is the `denominator` of our average)\n","3. return `x = numerator/denoninator` , the average\n","\n","Note: You can look at [expand](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html) in pytorch."]},{"cell_type":"markdown","metadata":{"id":"M0aq_l_f4xiv"},"source":["#### Defining the architecture for Deep Averaging Networks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1q7oqyrCP8fK"},"outputs":[],"source":["import random as random\n","\n","class DAN(nn.Module):\n","\n","    def __init__(self,\n","                 n_embed=20000,\n","                 d_embed=300,\n","                 d_hidden=100,\n","                 d_out=2,\n","                 layer_dropout = 0.2,\n","                 word_dropout = 0.3,\n","                 embeddings=None,\n","                 depth = 0):\n","        super(DAN, self).__init__()\n","\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.embed = create_emb_layer(weights_matrix,False)\n","\n","        self.fc_out = nn.Linear(d_hidden, d_out)\n","        self.word_dropout = word_dropout\n","\n","    def masked_mean(self,v, mask):\n","        \"\"\"\n","        Create the masked mean\n","\n","        INPUT:\n","        v       - input\n","        mask    - mask that has 0 and 1 for all the tokens in the input\n","                  0 corresponds to a token we should not include in the average and 1 otherwise\n","\n","        OUTPUT:\n","        x       - average\n","\n","        \"\"\"\n","        (batch, max_sent, d_embed ) = v.size() #these values we will be useful for expanding the mask\n","        #### STUDENT CODE HERE ####\n","        mask = mask.view(batch, max_sent, 1).expand(batch, max_sent, d_embed).float()  # change the view of the mask so it extends to the embeddings size\n","        den = mask.sum(dim=1).expand(batch, d_embed)  # the number of surviving words\n","        num =  (v * mask).sum(dim=1)  # eliminate the tokens that aren't in the mask, and sum\n","        x = num / den #average\n","        #### STUDENT CODE ENDS HERE ####\n","        return x\n","\n","    def forward(self, text_ids, mask):\n","        embeddings = self.embed(text_ids) #this is a matrix of embeddings, one for each id, of size batch_size X max_sent_size X embedding dimension\n","        avg = self.masked_mean(embeddings,mask) #should return the average of the embeddings, ignoring the embeddings corresponding to the pad token\n","        output = self.fc_out(avg) #final classification layer\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"JmdzEvd2Nc2M"},"source":["#### Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MLxfgD7M-aI"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","\n","batch_size = 64\n","epochs = 3\n","dev_every = 100\n","lr = 0.001\n","save_path = \"best_model\"\n","drop_out = 0\n","word_dropout = 0.01\n","weight_decay = 1e-5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HK3X1nSxCB8g"},"outputs":[],"source":["\n","def train(lr = .005, drop_out = 0, word_dropout = .3, batch_size = 16, weight_decay = 1e-5,args = None):\n","    if args is not None:\n","      drop_out = args[\"drop_out\"]\n","      drop_out = args[\"drop_out\"]\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    trainset = SSTpytorchDataset(ds, word_dropout, 'train')\n","    testset = SSTpytorchDataset(ds, word_dropout, 'test')\n","    devset = SSTpytorchDataset(ds, word_dropout, 'dev')\n","\n","    train_iter = DataLoader(trainset, batch_size, shuffle=True, num_workers=0)\n","    test_iter = DataLoader(testset, batch_size, shuffle=False, num_workers=0)\n","    dev_iter = DataLoader(devset, batch_size, shuffle=False, num_workers=0)\n","\n","    model = DAN(n_embed=n_embed, d_embed=d_embed, d_hidden=300, d_out=d_out, layer_dropout=drop_out, word_dropout = word_dropout )\n","    model.to(device)\n","\n","    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n","\n","\n","    acc, val_loss = evaluate(dev_iter, model, device)\n","    best_acc = acc\n","\n","    print(\n","        'epoch |   %        |  loss  |  avg   |val loss|   acc   |  best  | time | save |')\n","    print(\n","        'val   |            |        |        | {:.4f} | {:.4f} | {:.4f} |      |      |'.format(\n","            val_loss, acc, best_acc))\n","\n","    iterations = 0\n","    last_val_iter = 0\n","    train_loss = 0\n","    start = time.time()\n","    _save_ckp = ''\n","    for epoch in range(epochs):\n","        # train_iter.init_epoch()\n","        n_correct, n_total, train_loss = 0, 0, 0\n","        last_val_iter = 0\n","        for batch_idx, batch in enumerate(train_iter):\n","            # switch model to training mode, clear gradient accumulators\n","            model.train();\n","            optimizer.zero_grad()\n","\n","            iterations += 1\n","\n","            data, ns, mask, label = batch\n","\n","            data = data.to(device)\n","            label = label.to(device).long()\n","            mask = mask.to(device).long()\n","            mask.requires_grad = False\n","\n","            answer = model(data,mask)\n","            loss = criterion(answer, label)\n","\n","            loss.backward();\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            print('\\r {:4d} | {:4d}/{} | {:.4f} | {:.4f} |'.format(\n","                epoch, batch_size * (batch_idx + 1), len(trainset), loss.item(),\n","                       train_loss / (iterations - last_val_iter)), end='')\n","\n","            if iterations > 0 and iterations % dev_every == 0:\n","                acc, val_loss= evaluate(dev_iter, model, device)\n","\n","                if acc > best_acc:\n","                    best_acc = acc\n","                    torch.save(model.state_dict(), save_path)\n","                    _save_ckp = '*'\n","\n","                print(\n","                    ' {:.4f} | {:.4f} | {:.4f} | {:.2f} | {:4s} |'.format(\n","                        val_loss, acc, best_acc, (time.time() - start) / 60,\n","                        _save_ckp))\n","\n","                train_loss = 0\n","                last_val_iter = iterations\n","    model.load_state_dict(torch.load(save_path)) #this will be the best model\n","    test_y_pred = evaluate(test_iter,model, device,\"test\")\n","    print(\"\\nValidation Accuracy : \", evaluate(dev_iter,model, device))\n","    return best_acc, test_y_pred\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaMw5RMINjZd"},"outputs":[],"source":["\n","def evaluate(loader, model, device, split = \"dev\"):\n","    model.eval()\n","    n_correct, n = 0, 0\n","    losses = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for batch_idx, batch in enumerate(loader):\n","            data, ns, mask, label = batch\n","            data = data.to(device)\n","            label = label.to(device).long()\n","            mask = mask.to(device).long()\n","            answer = model(data,mask)\n","            if split != \"test\":\n","                n_correct += (torch.max(answer, 1)[1].view(label.size()) == label).sum().item()\n","                n += answer.shape[0]\n","                loss = criterion(answer, label)\n","                losses.append(loss.data.cpu().numpy())\n","            else:\n","                y_pred.extend(torch.max(answer, 1)[1].view(label.size()).tolist())\n","    if split != \"test\":\n","        acc = 100. * n_correct / n\n","        loss = np.mean(losses)\n","        return acc, loss\n","    else:\n","        return y_pred\n"]},{"cell_type":"markdown","metadata":{"id":"tFF_2GQXhqGz"},"source":["Run this to get the validation accuracy on the dev dataset and the predictions of the test dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64106,"status":"ok","timestamp":1701201499871,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"x7FkX-MDokS7","outputId":"dccb9248-1fa3-49d2-caa9-9186fc22a33a"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch |   %        |  loss  |  avg   |val loss|   acc   |  best  | time | save |\n","val   |            |        |        | 0.6847 | 56.3385 | 56.3385 |      |      |\n","    0 | 6400/98794 | 0.4591 | 0.5403 | 0.4624 | 79.0595 | 79.0595 | 0.02 | *    |\n","    0 | 12800/98794 | 0.3945 | 0.4178 | 0.3917 | 85.0099 | 85.0099 | 0.04 | *    |\n","    0 | 19200/98794 | 0.3145 | 0.3614 | 0.3609 | 84.1501 | 85.0099 | 0.06 | *    |\n","    0 | 25600/98794 | 0.2922 | 0.3234 | 0.3424 | 85.1697 | 85.1697 | 0.08 | *    |\n","    0 | 32000/98794 | 0.3396 | 0.2984 | 0.3318 | 85.4436 | 85.4436 | 0.11 | *    |\n","    0 | 38400/98794 | 0.2284 | 0.2922 | 0.3220 | 86.1437 | 86.1437 | 0.12 | *    |\n","    0 | 44800/98794 | 0.2427 | 0.2788 | 0.3209 | 85.3067 | 86.1437 | 0.14 | *    |\n","    0 | 51200/98794 | 0.2454 | 0.2730 | 0.3150 | 85.9382 | 86.1437 | 0.16 | *    |\n","    0 | 57600/98794 | 0.2371 | 0.2600 | 0.3166 | 85.2838 | 86.1437 | 0.18 | *    |\n","    0 | 64000/98794 | 0.2075 | 0.2544 | 0.3161 | 85.3447 | 86.1437 | 0.19 | *    |\n","    0 | 70400/98794 | 0.2239 | 0.2458 | 0.3139 | 85.8773 | 86.1437 | 0.21 | *    |\n","    0 | 76800/98794 | 0.3159 | 0.2582 | 0.3235 | 84.7207 | 86.1437 | 0.23 | *    |\n","    0 | 83200/98794 | 0.1535 | 0.2454 | 0.3126 | 85.8165 | 86.1437 | 0.24 | *    |\n","    0 | 89600/98794 | 0.2301 | 0.2507 | 0.3150 | 85.6262 | 86.1437 | 0.26 | *    |\n","    0 | 96000/98794 | 0.2615 | 0.2558 | 0.3057 | 86.2198 | 86.2198 | 0.28 | *    |\n","    1 | 3584/98794 | 0.2693 | 0.0072 | 0.3072 | 86.4024 | 86.4024 | 0.30 | *    |\n","    1 | 9984/98794 | 0.2836 | 0.1946 | 0.3106 | 86.6383 | 86.6383 | 0.32 | *    |\n","    1 | 16384/98794 | 0.1441 | 0.2017 | 0.3129 | 86.0219 | 86.6383 | 0.34 | *    |\n","    1 | 22784/98794 | 0.1138 | 0.2027 | 0.3153 | 85.6491 | 86.6383 | 0.36 | *    |\n","    1 | 29184/98794 | 0.2405 | 0.1890 | 0.3159 | 86.4556 | 86.6383 | 0.38 | *    |\n","    1 | 35584/98794 | 0.1740 | 0.2043 | 0.3200 | 85.6795 | 86.6383 | 0.39 | *    |\n","    1 | 41984/98794 | 0.1808 | 0.2010 | 0.3153 | 86.5393 | 86.6383 | 0.41 | *    |\n","    1 | 48384/98794 | 0.0978 | 0.1982 | 0.3186 | 86.2882 | 86.6383 | 0.42 | *    |\n","    1 | 54784/98794 | 0.2296 | 0.1984 | 0.3266 | 85.4208 | 86.6383 | 0.44 | *    |\n","    1 | 61184/98794 | 0.1330 | 0.1945 | 0.3241 | 85.7023 | 86.6383 | 0.46 | *    |\n","    1 | 67584/98794 | 0.1805 | 0.1864 | 0.3232 | 85.7632 | 86.6383 | 0.47 | *    |\n","    1 | 73984/98794 | 0.1747 | 0.1810 | 0.3250 | 85.9915 | 86.6383 | 0.49 | *    |\n","    1 | 80384/98794 | 0.1531 | 0.1975 | 0.3247 | 85.7860 | 86.6383 | 0.51 | *    |\n","    1 | 86784/98794 | 0.2105 | 0.1940 | 0.3256 | 85.9230 | 86.6383 | 0.53 | *    |\n","    1 | 93184/98794 | 0.1451 | 0.1867 | 0.3285 | 85.6110 | 86.6383 | 0.55 | *    |\n","    2 |  768/98794 | 0.2172 | 0.0007 | 0.3267 | 85.9534 | 86.6383 | 0.57 | *    |\n","    2 | 7168/98794 | 0.1276 | 0.1469 | 0.3307 | 86.0676 | 86.6383 | 0.59 | *    |\n","    2 | 13568/98794 | 0.0816 | 0.1504 | 0.3293 | 86.2578 | 86.6383 | 0.61 | *    |\n","    2 | 19968/98794 | 0.1708 | 0.1611 | 0.3353 | 86.0447 | 86.6383 | 0.62 | *    |\n","    2 | 26368/98794 | 0.1316 | 0.1575 | 0.3401 | 85.6795 | 86.6383 | 0.64 | *    |\n","    2 | 32768/98794 | 0.1456 | 0.1573 | 0.3429 | 85.8165 | 86.6383 | 0.66 | *    |\n","    2 | 39168/98794 | 0.1557 | 0.1712 | 0.3460 | 85.8697 | 86.6383 | 0.67 | *    |\n","    2 | 45568/98794 | 0.2442 | 0.1476 | 0.3500 | 85.8317 | 86.6383 | 0.69 | *    |\n","    2 | 51968/98794 | 0.1201 | 0.1656 | 0.3511 | 85.9534 | 86.6383 | 0.71 | *    |\n","    2 | 58368/98794 | 0.1343 | 0.1672 | 0.3501 | 85.9230 | 86.6383 | 0.72 | *    |\n","    2 | 64768/98794 | 0.1337 | 0.1738 | 0.3534 | 85.7936 | 86.6383 | 0.74 | *    |\n","    2 | 71168/98794 | 0.1076 | 0.1711 | 0.3515 | 85.7175 | 86.6383 | 0.76 | *    |\n","    2 | 77568/98794 | 0.2181 | 0.1729 | 0.3535 | 85.6034 | 86.6383 | 0.78 | *    |\n","    2 | 83968/98794 | 0.2662 | 0.1718 | 0.3555 | 85.3067 | 86.6383 | 0.80 | *    |\n","    2 | 90368/98794 | 0.2020 | 0.1636 | 0.3550 | 85.5273 | 86.6383 | 0.82 | *    |\n","    2 | 96768/98794 | 0.2565 | 0.1814 | 0.3530 | 85.6262 | 86.6383 | 0.84 | *    |\n","    2 | 98816/98794 | 0.1313 | 0.1717 |\n","Validation Accuracy :  (86.6382590168924, 0.310589)\n"]}],"source":["torch.manual_seed(1234)\n","\n","epochs = 3\n","dev_value, test_y_pred = train(lr, batch_size, word_dropout, batch_size, weight_decay)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1701201500461,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"Z1hq5605hbjx","outputId":"c69a21fc-2b0e-4fbb-e546-5591e196bf99"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 20/20 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_dan_predictions', answer = test_y_pred)"]},{"cell_type":"markdown","metadata":{"id":"4tAw9tgbGY1D"},"source":["## 1.2 Transformer [10 pts, Autograded]\n","\n","In Lecture 18 we have discussed the heated model architecture Transformers. The original paper that proposed Transformer is [Attention Is All You Need (Vaswani et al. 2017)](https://arxiv.org/abs/1706.03762), and you can read it if interested.\n","\n","Recall that it is a composition of self-attention layers, here is a graph representation of the architecture:\n","![transformer architecture](https://d2l.ai/_images/transformer.svg)\n","\n","So the idea of self-attention is essential for Transformers, and in this homework question your task is to implement the multi-head attention block in a Transformer."]},{"cell_type":"markdown","metadata":{"id":"bP0L25asIZvl"},"source":["### 1.2.1 Helper functions\n","\n","There is no code that you need to write here, but you do need to run this section!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfesBhaeH7vy"},"outputs":[],"source":["# importing required libraries\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","import math,copy,re\n","import warnings\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import torchtext\n","import matplotlib.pyplot as plt\n","warnings.simplefilter(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyqPvjUtGdn0"},"outputs":[],"source":["cur_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","class PositionalEncoder(nn.Module):\n","    def __init__(self, embed_dim, max_len=300, device=cur_device):\n","        super().__init__()\n","        self.position_embedding = torch.zeros((1, max_len, embed_dim)).to(device)\n","        i = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1)\n","        j2 = torch.arange(0, embed_dim, step=2, dtype=torch.float32)\n","        x = i / torch.pow(10000, j2 / embed_dim)\n","        self.position_embedding[..., 0::2] = torch.sin(x)\n","        self.position_embedding[..., 1::2] = torch.cos(x)\n","\n","    def forward(self, x):\n","        x_plus_p = x + self.position_embedding[:, : x.shape[1]]\n","        return x_plus_p"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tMbEDKEkJQ2J"},"outputs":[],"source":["class ResidualNorm(nn.Module):\n","    def __init__(self, embed_dim):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x, residual):\n","        return self.norm(x + residual)\n","\n","\n","class Feedforward(nn.Module):\n","    def __init__(self, embed_dim, hidden_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, embed_dim)\n","\n","    def forward(self, x):\n","        return self.fc2(F.relu(self.fc1(x)))"]},{"cell_type":"markdown","metadata":{"id":"1goKvQT7JgQK"},"source":["### 1.2.2 Multihead Attention [TODO: 10 pts]\n","\n","Recall that the attention mechanism requires three main components:\n","\n"," - the values vectors V\n"," - the query vectors Q\n"," - the key vectors K\n","\n"," And for self-attention, these are all calulated from the original input using three different learnable weight matrices. Essentially we are trying to see that how similar are my queries and keys and use this attention score to construct a weight sum of my values.\n","\n"," As for Multihead attention, each head will attend to a set of (V, Q, K) values, so we need to replicate (V, Q, K) n times if we have n number of attention heads. This is done by our helper function `mha_transform_input`. You will also need to transform the output back to the correct size at the end to make sure that it can be used as input to future layers using `mha_transform_output`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-z2RSkbcJbPi"},"outputs":[],"source":["def masked_softmax(x, mask):\n","    \"\"\"Applies softmax on a masked version of the input.\n","    Args:\n","      x (n_batch, n_tokens, n_tokens): - the scaled dot product of Q and K\n","      mask (n_batch, n_tokens): - binary mask, all values = 0 will be set to -inf\n","    Returns:\n","      (n_batch, n_tokens, n_tokens): the result of applying softmax along the last\n","        dimension of the masked input.\n","    \"\"\"\n","    return F.softmax(x.masked_fill_(mask.unsqueeze(1) == 0, float(\"-inf\")), dim=-1)\n","\n","\n","def mha_transform_input(x, n_heads, head_dim):\n","    \"\"\"Restructure the input tensors to compute the heads in parallel\n","    Requires that head_dim = embed_dim / n_heads\n","    Args:\n","      x (n_batch, n_tokens, embed_dim): input tensor, one of queries, keys, or values\n","      n_heads (int): the number of attention heads\n","      head_dim (int): the dimensionality of each head\n","    Returns:\n","      (n_batch*n_heads, n_tokens, head_dim): 3D Tensor containing all the input heads\n","    \"\"\"\n","    n_batch, n_tokens, _ = x.shape\n","    x = x.reshape((n_batch, n_tokens, n_heads, head_dim))\n","    x = x.permute(0, 2, 1, 3)\n","    return x.reshape((n_batch * n_heads, n_tokens, head_dim))\n","\n","\n","def mha_transform_output(x, n_heads, head_dim):\n","    \"\"\"Restructures the output back to the original format\n","    Args:\n","      x (n_bacth*n_heads, n_tokens, head_dim): multi-head representation tensor\n","      n_heads (int): the number of attention heads\n","      head_dim (int): the dimensionality of each head\n","    Returns:\n","      (n_batch, n_tokens, embed_dim): 3D Tensor containing all the input heads\n","    \"\"\"\n","    n_concat, n_tokens, _ = x.shape\n","    n_batch = n_concat // n_heads\n","    x = x.reshape((n_batch, n_heads, n_tokens, head_dim))\n","    x = x.permute(0, 2, 1, 3)\n","    return x.reshape((n_batch, n_tokens, n_heads * head_dim))\n","\n","\n","class ScaledDotProductAttention(nn.Module):\n","    def __init__(self, embed_dim):\n","        super().__init__()\n","        self.embed_dim = embed_dim\n","\n","    def forward(self, queries, keys, values, mask):\n","        \"\"\"\n","        Args:\n","          queries (n_batch, n_tokens, embed_dim): queries (Q) tensor\n","          keys (n_batch, n_tokens, embed_dim): keys (K) tensor\n","          values (n_batch, n_tokens, embed_dim): values (V) tensor\n","          mask (n_batch, n_tokens): binary mask tensor\n","        Returns:\n","          (n_batch, n_tokens, embed_dim): scaled dot product attention tensor\n","        \"\"\"\n","        #### STUDENT CODE HERE ####\n","        # 1. Calculate the batched dot product of queries and keys\n","        pro_dot=torch.bmm(queries, keys.transpose(-2,-1))\n","        # 2. Scale it by the square root of embedding dimensions\n","        pro_dot_scale= pro_dot / math.sqrt(self.embed_dim)\n","\n","\n","        # 3. Pass the scaled dot product through masked_softmax to get attention weights\n","        weight_atten=masked_softmax(pro_dot_scale,mask)\n","\n","\n","        # 4. Compute final attention using the attention weights and values\n","        attention = torch.matmul(weight_atten,values)\n","\n","        #### STUDENT CODE ENDS HERE ####\n","        return attention\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, n_heads, embed_dim):\n","        super().__init__()\n","        self.n_heads = n_heads\n","        self.head_dim = embed_dim // n_heads\n","\n","        self.attention = ScaledDotProductAttention(embed_dim)\n","\n","        #### STUDENT CODE HERE ####\n","        # Define the weight matrices for each of Q, K, and V\n","        # Please strictly follow this order of initialization\n","        # You can do this with fully connected linear layers\n","        # Remember to set bias=False to make sure that it is pure weight matrices\n","        self.query_fc =nn.Linear(embed_dim, embed_dim, bias=False)\n","        self.key_fc =nn.Linear(embed_dim, embed_dim, bias=False)\n","        self.value_fc =nn.Linear(embed_dim, embed_dim, bias=False)\n","\n","\n","        #### STUDENT CODE ENDS HERE ####\n","\n","        self.out_fc = nn.Linear(embed_dim, embed_dim, bias=False)\n","\n","    def forward(self, queries, keys, values, mask):\n","        \"\"\"\n","        Args:\n","          queries (n_batch, n_tokens, embed_dim): queries (Q) tensor\n","          keys (n_batch, n_tokens, embed_dim): keys (K) tensor\n","          values (n_batch, n_tokens, embed_dim): values (V) tensor\n","          mask (n_batch, n_tokens): binary mask tensor\n","        Returns:\n","          (n_batch, n_tokens, embed_dim): multi-head attention tensor\n","        \"\"\"\n","        #### STUDENT CODE HERE ####\n","        # For each of V, Q, and K\n","        # 1. Multiply its corresponding weight matrix (passing through the Linear layer)\n","        q = self.query_fc(queries)\n","        k = self.key_fc(keys)\n","        v = self.value_fc(values)\n","\n","        # 2. Use mha_transform_input to transform it into multihead\n","        q = mha_transform_input(q, self.n_heads, self.head_dim)\n","        k = mha_transform_input(k, self.n_heads, self.head_dim)\n","        v = mha_transform_input(v, self.n_heads, self.head_dim)\n","\n","        # 3. Calculate the attention results\n","        attention = self.attention(q, k, v, mask)\n","        # 4. Use mha_transform_output to transform it back into the correct size\n","        attention = mha_transform_output(attention, self.n_heads, self.head_dim)\n","        # 5. Pass the results through the output fully connect layer\n","        attention = self.out_fc(attention)\n","        #### STUDENT CODE ENDS HERE ####\n","        return attention"]},{"cell_type":"markdown","metadata":{"id":"CufZYbn9Qk8y"},"source":["#### Test your Multihead Attention implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UhjesZP1Q_H8"},"outputs":[],"source":["embed_dim = 1\n","my_scaled = ScaledDotProductAttention(embed_dim)\n","\n","torch.manual_seed(522)\n","src_tokens = torch.Tensor([[[7],[8],[5],[1],[10]]]).to(cur_device)\n","src_mask = torch.IntTensor([[1,1,1,1,0]]).to(cur_device)\n","\n","# HINT: scaled_answer should have shape (1, 5, 1)\n","scaled_answer = my_scaled(src_tokens, src_tokens, src_tokens, src_mask).cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1701203381328,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"qviZw4JPmuYq","outputId":"cea681f9-4c45-4be5-a081-84a52242886c"},"outputs":[{"data":{"text/plain":["array([[[7.9990892],\n","        [7.999665 ],\n","        [7.9933057],\n","        [7.6308813],\n","        [7.999954 ]]], dtype=float32)"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["scaled_answer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":632,"status":"ok","timestamp":1701203383797,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"gR7T3nQeVWIg","outputId":"189f72b2-9e12-4b2f-f989-0bc14da66422"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 4/4 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_scaled_dot_product', answer = scaled_answer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EuKeYAMpQcg1"},"outputs":[],"source":["n_heads = 2\n","embed_dim = 2\n","my_att = MultiHeadAttention(n_heads, embed_dim)\n","\n","torch.manual_seed(522)\n","src_tokens = torch.Tensor([[[2, 7],[3, 8],[4, 5],[9, 1],[2, 10]]])\n","src_mask = torch.IntTensor([[1,1,1,1,0]])\n","\n","# HINT: att_answer should have shape (1, 5, 2)\n","att_answer = my_att(src_tokens, src_tokens, src_tokens, src_mask).detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1701203367076,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"QJBV2VJ_gsn0","outputId":"9cc598d5-ba49-4f98-e94d-795789944e63"},"outputs":[{"data":{"text/plain":["array([[[-0.70935756, -1.1572802 ],\n","        [-0.7208823 , -1.2223326 ],\n","        [-0.68117696, -0.72287667],\n","        [-0.6035587 ,  0.32271206],\n","        [-0.73480195, -1.3823562 ]]], dtype=float32)"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["att_answer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":466,"status":"ok","timestamp":1701203368431,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"QR4fxUXBXN7e","outputId":"49ede414-eeef-4da5-98a9-65132b02822d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 4/4 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_multihead_attention', answer = att_answer)"]},{"cell_type":"markdown","metadata":{"id":"FK8IoX2EOpWv"},"source":["#### Other part of the Transformers code\n","\n","Run this!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l96uiPyUOgg9"},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self, n_heads, embed_dim, hidden_dim):\n","        super().__init__()\n","        self.attention = MultiHeadAttention(n_heads, embed_dim)\n","        self.norm1 = ResidualNorm(embed_dim)\n","        self.feedforward = Feedforward(embed_dim, hidden_dim)\n","        self.norm2 = ResidualNorm(embed_dim)\n","\n","    def forward(self, src_tokens, src_mask):\n","        \"\"\"\n","        Args:\n","          src_tokens (n_batch, n_tokens, embed_dim): the source sequence\n","          src_mask (n_batch, n_tokens): binary mask over the source\n","        Returns:\n","          (n_batch, n_tokens, embed_dim): the encoder state\n","        \"\"\"\n","        # First compute self-attention on the source tokens by passing them in\n","        # as the queries, keys, and values to the attention module.\n","        self_attention = self.attention(src_tokens, src_tokens, src_tokens, src_mask)\n","        # Next compute the norm of the self-attention result with a residual\n","        # connection from the source tokens\n","        normed_attention = self.norm1(self_attention, src_tokens)\n","        # Pass the normed attention result through the feedforward component\n","        ff_out = self.feedforward(normed_attention)\n","        # Finally compute the norm of the feedforward output with a residual\n","        # connection from the normed attention output\n","        out = self.norm2(ff_out, normed_attention)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Tq2PTyUOvAl"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim, n_heads, n_blocks):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim).to(cur_device)\n","        self.positional_encoding = PositionalEncoder(embed_dim).to(cur_device)\n","        self.encoder_blocks = nn.ModuleList(\n","            [EncoderBlock(n_heads, embed_dim, hidden_dim) for _ in range(n_blocks)]\n","        ).to(cur_device)\n","\n","    def forward(self, src_tokens, src_mask):\n","        x = self.embedding(src_tokens)\n","        x = self.positional_encoding(x)\n","        for block in self.encoder_blocks:\n","            x = block(x, src_mask)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"svwo2qeVO7Ke"},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","    def __init__(self, n_heads, embed_dim, hidden_dim):\n","        super().__init__()\n","        self.self_attention = MultiHeadAttention(n_heads, embed_dim)\n","        self.norm1 = ResidualNorm(embed_dim)\n","        self.encoder_attention = MultiHeadAttention(n_heads, embed_dim)\n","        self.norm2 = ResidualNorm(embed_dim)\n","        self.feedforward = Feedforward(embed_dim, hidden_dim)\n","        self.norm3 = ResidualNorm(embed_dim)\n","\n","    def forward(self, tgt_tokens, tgt_mask, encoder_state, src_mask):\n","        \"\"\"\n","        Args:\n","          tgt_tokens (n_batch, n_tokens, embed_dim): the target sequence\n","          tgt_mask (n_batch, n_tokens): binary mask over the target tokens\n","          encoder_state (n_batch, n_tokens, embed_dim): the output of the encoder pass\n","          src_mask (n_batch, n_tokens): binary mask over the source tokens\n","        Returns:\n","          (n_batch, n_tokens, embed_dim): the decoder state\n","        \"\"\"\n","        # First compute self-attention on the target tokens by passing them in\n","        # as the queries, keys, and values to the attention module along with the\n","        # target mask.\n","        self_attention = self.self_attention(tgt_tokens, tgt_tokens, tgt_tokens, tgt_mask)\n","        # Next compute the norm of the self-attention result with a residual\n","        # connection from the target tokens\n","        normed_self_attention = self.norm1(self_attention, tgt_tokens)\n","        # Compute the encoder attention by using the normed self-attention output as\n","        # the queries and the encoder state as the keys and values along with the\n","        # source mask.\n","        encoder_attention = self.encoder_attention(normed_self_attention, encoder_state, encoder_state, src_mask)\n","        # Next compute the norm of the encoder attention result with a residual\n","        # connection from the normed self-attention\n","        normed_encoder_attention = self.norm2(encoder_attention, normed_self_attention)\n","        # Pass the normed encoder attention result through the feedforward component\n","        ff_out = self.feedforward(normed_encoder_attention)\n","        # Finally compute the norm of the feedforward output with a residual\n","        # connection from the normed attention output\n","        out = self.norm3(ff_out, normed_encoder_attention)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgLIgcCPPBSX"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim, n_heads, n_blocks):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim).to(cur_device)\n","        self.positional_encoding = PositionalEncoder(embed_dim).to(cur_device)\n","        self.decoder_blocks = nn.ModuleList(\n","            [DecoderBlock(n_heads, embed_dim, hidden_dim) for _ in range(n_blocks)]\n","        ).to(cur_device)\n","\n","    def forward(self, tgt_tokens, tgt_mask, encoder_state, src_mask):\n","        x = self.embedding(tgt_tokens)\n","        x = self.positional_encoding(x)\n","        for block in self.decoder_blocks:\n","            x = block(x, tgt_mask, encoder_state, src_mask)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nBwmZ0qPO8y"},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(\n","        self, src_vocab_size, tgt_vocab_size, embed_dim, hidden_dim, n_heads, n_blocks\n","    ):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab_size, embed_dim, hidden_dim, n_heads, n_blocks)\n","        self.decoder = Decoder(tgt_vocab_size, embed_dim, hidden_dim, n_heads, n_blocks)\n","        self.out = nn.Linear(embed_dim, tgt_vocab_size).to(cur_device)\n","\n","    def forward(self, src_tokens, src_mask, tgt_tokens, tgt_mask):\n","        # Compute the encoder output state from the source tokens and mask\n","        encoder_state = self.encoder(src_tokens, src_mask)\n","        # Compute the decoder output state from the target tokens and mask as well\n","        # as the encoder state and source mask\n","        decoder_state = self.decoder(tgt_tokens, tgt_mask, encoder_state, src_mask)\n","        # Compute the vocab scores by passing the decoder state through the output\n","        # linear layer\n","        out = self.out(decoder_state)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"SdRKWXXkPgTR"},"source":["#### Test your implementation works with the entire Transformer implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQx8lWdhPZV6"},"outputs":[],"source":["# Test for Transformer\n","torch.manual_seed(522)\n","src_vocab_size = tgt_vocab_size = 5\n","n_blocks, n_heads, batch_size, embed_dim, hidden_dim = 10, 2, 1, 4, 8\n","src_tokens = tgt_tokens = torch.IntTensor([[0,1,2,3,4]]).to(cur_device)\n","src_mask = tgt_mask = torch.IntTensor([[1,1,1,1,1]]).to(cur_device)\n","\n","transformer = Transformer(src_vocab_size, tgt_vocab_size, embed_dim, hidden_dim, n_heads, n_blocks)\n","\n","# HINT: trans_answer should have shape (1, 5, 5)\n","trans_answer = transformer(src_tokens, src_mask, tgt_tokens, tgt_mask).cpu().detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701203404466,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"CsgAZRfuiCtR","outputId":"78658784-fe37-4376-b9c2-30127dba519d"},"outputs":[{"data":{"text/plain":["(1, 5, 5)"]},"execution_count":118,"metadata":{},"output_type":"execute_result"}],"source":["trans_answer.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1701203404812,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"FowQZP0YYYE6","outputId":"2263af38-af14-4d22-b488-b8ce7f985db0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 2/2 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_transformer', answer = trans_answer)"]},{"cell_type":"markdown","metadata":{"id":"iR-DGV_94HJx"},"source":["#2.Reinforcement Learning Section [18pts Autograded, 4pts Manually graded]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62653,"status":"ok","timestamp":1701201565026,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"mloN11-laGA6","outputId":"4a1d9dda-2f17-4b46-eb7c-9a5cefd21db6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [47.2 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n","Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,250 kB]\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,498 kB]\n","Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:14 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,244 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,016 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,472 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,521 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,284 kB]\n","Get:19 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,152 kB]\n","Get:20 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [39.5 kB]\n","Fetched 11.8 MB in 2s (5,559 kB/s)\n","Reading package lists... Done\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m858.3/858.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.2).\n","0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"]}],"source":["\"\"\"\n","installing dependencies\n","\"\"\"\n","!apt-get update\n","!apt-get -qq -y install libnvtoolsext1 > /dev/null\n","!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n","!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n","!pip -q install gym[classic_control]\n","!pip -q install pyglet\n","!pip -q install pyopengl\n","!pip -q install pyvirtualdisplay\n","!apt-get install xvfb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M_8V6fYxaH6x"},"outputs":[],"source":["\"\"\"\n","Imports\n","\"\"\"\n","\n","import gym\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from collections import deque\n","import random\n","from gym import wrappers\n","import torch\n","from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(1024, 768))\n","display.start()\n","import os\n","\n","import matplotlib.animation\n","import numpy as np\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701201566879,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"WR-sHW-Yae3w","outputId":"52663f72-35f3-4625-853d-4f604eff3439"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["## Wrapper for Rendering the Environment\n","\n","class ResizeObservation(gym.Wrapper):\n","    def __init__(self, env, shape):\n","        super(ResizeObservation, self).__init__(env)\n","        if isinstance(shape, int):\n","            shape = (shape, shape)\n","        assert all(x > 0 for x in shape), shape\n","        self.env = env\n","        self.shape = tuple(shape)\n","\n","    def render(self):\n","\n","        from PIL import Image\n","        obs = self.env.render(mode = 'rgb_array')\n","        im = Image.fromarray(np.uint8(obs))\n","        im = im.resize(self.shape)\n","        return np.asarray(im)\n","\n","resize_observation_shape = 100\n"]},{"cell_type":"markdown","metadata":{"id":"10aD0AWF5LvF"},"source":["### 2.1 Discretize the state [TODO: 3pts]"]},{"cell_type":"markdown","metadata":{"id":"DPREgT6I5MU1"},"source":["The state of Mountain Car is represented by a vector of 2 (float) values. The first element of the state vector represents the cart’s position, and the second element represents the cart’s velocity. You can use `env.observation_space.low` and `env.observation_space.high` to find out its upper and lower bound.\n","\n","\n","As you can see the state space of the Mountain Car is continuous, which means that there are infinitely many state-action pairs , making basic Q-learning impossible to satisfy this condition. Instead, for a simple environment like Mountain Car, we can discretize the continuous state space and round the state to nearest discretization state. Then use the discretization state as the index of Q value matrix.\n","\n","For example, let us say you have a continuous state with range of [0.5, 1], and you want to discretize it in the range [1, 100] (only integers). You have to linearly map the continuous interval [0.5, 1] to the discrete interval [1, 100], therefore a number like .75 would go to 25.\n","\n","The linear mapping from a continuous value $c$ to its equivalent discrete value $d$ would be expressed as:\n","\n","$$d = \\text{round}\\left((c - state.minimum) * discretization scale \\right)$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8WtSP845IZQ"},"outputs":[],"source":["def discretize(state, discretization, env):\n","    \"\"\"\n","    Discretize the continuous state to a given discretization range.\n","    Args:\n","        state (np.array, shape=(2,)): the observation state, here it is [position, velocity]\n","        discretization(np.array, shape=(2,)): the discretization ,by default, it is np.array([100,10])\n","        env: the RL environment\n","\n","    Returns:\n","        discretized_state (np.array, shape=(2,), dtype=int): the discretized state\n","    \"\"\"\n","\n","    #### STUDENT CODE HERE ####\n","\n","    #subtract low_state from state, then multiply elementwise by discretization vector\n","    discretized_state = np.round((state - env.observation_space.low) * discretization)\n","    #round elements of discretized state to ints\n","    discretized_state = discretized_state.astype(int)\n","    #### STUDENT CODE ENDS HERE ####\n","\n","    return discretized_state"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1701203841878,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"-lTigjq65E3P","outputId":"97d0a6e6-5fa8-440d-bfdf-5132b0ca72d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[176   7]\n","Well done\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}],"source":["def test_discretization():\n","    test_state = np.array([0.556, 0.6])\n","    discretization = np.array([100, 10])\n","    env = gym.make('MountainCar-v0')\n","    env = ResizeObservation(env, resize_observation_shape)\n","    d = discretize(test_state, discretization, env)\n","    print(d)\n","    if d.shape != tuple([2]) or d[0] != 176 or d[1] != 7:\n","        print(\"Incorrect discretization\")\n","    else:\n","        print(\"Well done\")\n","\n","test_discretization()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":512,"status":"ok","timestamp":1701203846052,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"TiIhvQKp5F6a","outputId":"aa3edbc7-c88d-4d45-ef2a-2aba651977d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 3/3 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","test = np.array([.12,.56])\n","space = np.array([6,20])\n","env = gym.make('MountainCar-v0')\n","d = discretize(test, space, env)\n","grader.grade(test_case_id = 'test_discretize', answer = d)"]},{"cell_type":"markdown","metadata":{"id":"p6UqMyZxa4G4"},"source":["### 2.2 Choose action for a certain state [TODO: 2pts]"]},{"cell_type":"markdown","metadata":{"id":"GWvIaFHHa9TM"},"source":["Suppose now you are already given a state and a certain Q value matrix, the naive way is just choosing the action with highest Q value. However, in the real world it's better to consider the randomness of the action while learning, it could lead to a more robust controller and also let agent explore the environment.\n","\n","In this part, you need to implement an **epsilon greedy strategy** to choose action for a certain state.  **Epsilon greedy strategy** means that, given a threshold epsilon (between 0 and 1), your controller would have the probability of epsilon of just outputing a random action. For the rest of the time, it chooses the action with highest Q value.\n","\n","Implement this strategy in the `choose_action` function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"15YRXq2IbBWj"},"outputs":[],"source":["def choose_action(epsilon, Q, state, env):\n","    \"\"\"\n","    Choose an action according to an epsilon greedy strategy.\n","    Args:\n","        epsilon (float): the probability of choosing a random action\n","        Q (np.array): The Q value matrix, here it is 3D for the two observation states and action states\n","        state (np.array): the observation state, here it is [position, velocity]\n","        env: the RL environment\n","\n","    Returns:\n","        action (int): the chosen action\n","    \"\"\"\n","    action = 0\n","    random.seed(42)\n","    #### STUDENT CODE HERE ####\n","    out=np.random.random()\n","    if out<epsilon:\n","      action=np.random.randint(0, env.action_space.n)\n","    else:\n","      action=np.argmax(Q[state[0], state[1]])\n","\n","    #### STUDENT CODE ENDS HERE ####\n","\n","    return action\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701204295888,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"gsKG_0TBbKla","outputId":"e97e20cf-901e-436e-84f9-31de4b408444"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looks nondeterministic\n","Looks like the right shape\n"]}],"source":["\n","def test_choose_action_shape():\n","    Q = np.random.uniform(low = -1,\n","                        high = 1,\n","                        size = (100, 10, env.action_space.n))\n","    a = [choose_action(0.7, Q, (5, 3), env) for i in range(1000)]\n","    if type(a[0]) == int and a[0] < env.action_space.n:\n","        print(\"Looks like the right shape\")\n","    else:\n","        print(\"Incorrect return value (wrong type or higher than the number of action types)\")\n","\n","def test_choose_action_nondeterminacy():\n","    Q = np.random.uniform(low = -1, high = 1, size = (100, 10, env.action_space.n)) #added this in myself since Q was never defined before (I think a bug?)\n","    a = [choose_action(0.7, Q, (5, 3), env) for i in range(1000)]\n","    if len(set(a)) > 1:\n","        print(\"Looks nondeterministic\")\n","    else:\n","        print(\"Probably too deterministic\")\n","\n","test_choose_action_nondeterminacy()\n","test_choose_action_shape()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1701204229762,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"ruZ4eTd0ZuIP","outputId":"7d81d742-e74e-4b60-8a52-50fe478230e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 2/2 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["from numpy.random.mtrand import seed\n","# PennGrader Grading Cell\n","np.random.seed(42)\n","Q = np.random.uniform(low = -1,\n","                    high = 1,\n","                    size = (100, 10, env.action_space.n))\n","a = [choose_action(0.7, Q, (5, 3), env) for i in range(10)]\n","grader.grade(test_case_id = 'test_choose_action', answer = a)"]},{"cell_type":"markdown","metadata":{"id":"vxVrMtGWf3ir"},"source":["### 2.3 Decay epsilon [TODO: 1pts]"]},{"cell_type":"markdown","metadata":{"id":"bJXKfCpCf4U7"},"source":["In the Q-learning, we want the agent to explore the environment while efficiently reach the goal.\n","\n","Therefore, we usually set a high epsilon at the beginning of each trajectory, and decay the epsilon in the following steps.\n","\n","Implement the decay epsilon function for a certain step in the `update_epsilon` function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muGcECXEf8g5"},"outputs":[],"source":["def update_epsilon(epsilon, decay_rate):\n","    \"\"\"\n","    Decay epsilon by the specified rate. Note: it should be just one line of code.\n","\n","    Args:\n","        epsilon (float): the probability of choosing a random action\n","        decay_rate (float): the decay rate (between 0 and 1) to scale epsilon by\n","\n","    Returns:\n","        updated epsilon\n","    \"\"\"\n","\n","    #### STUDENT CODE HERE ####\n","    epsilon =epsilon * decay_rate\n","\n","    #### STUDENT CODE ENDS HERE ####\n","\n","\n","    return epsilon\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1701204360566,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"hQfFJt65f9Dz","outputId":"8554cf5c-7487-41e5-8148-bfbc72e66d49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Implementation of update_epsilon correct\n"]}],"source":["def testUpdateEpsilon():\n","    orig_ep = 0.51\n","    decay = 0.97\n","    new_ep = update_epsilon(orig_ep, decay)\n","    if not type(new_ep) == float:\n","        print(\"Wrong type returned\")\n","    elif new_ep != 0.4947:\n","        print(\"Incorrect implementation\")\n","    else:\n","        print(\"Implementation of update_epsilon correct\")\n","\n","testUpdateEpsilon()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444,"status":"ok","timestamp":1701204361651,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"INOA03Ibf-gQ","outputId":"1fd2159a-1090-420d-c791-817f1ee4b9fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 1/1 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_update_epsilon', answer = grader_serialize(update_epsilon))"]},{"cell_type":"markdown","metadata":{"id":"EPNHwEHTRT2L"},"source":["### 2.4 Update Q Value [5 pts]\n"]},{"cell_type":"markdown","metadata":{"id":"21QtD2igRUup"},"source":["Recall the incremental Q Value update function is:\n","\n","$$Q(s,a) = Q(s,a)+ \\alpha(R(s,a,s')+\\gamma\\max_{a'}Q(s',a')-Q(s,a) )$$\n","\n","Where $s$ is current state, $s'$ is next state, $a$ is current action, $a'$ is next possible action, $\\alpha$ is learning rate, $\\gamma$ is discount rate, $s'$ is next state. $Q(s,a)$ is Q value for a certain state and action pair, $R(s,a,s')$ is the reward of applying the state and action pair that arrive at $s'$. $Q(s',a')$ is the Q value of state action pair $(s',a')$. Implement the `update_qvalue` function."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":824,"status":"ok","timestamp":1701204520425,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"9KclPSQ9RX6U","outputId":"bf4f7300-87e4-4f51-bb91-239df8f4fc74"},"outputs":[{"name":"stdout","output_type":"stream","text":["Q update looks correct!\n"]}],"source":["def update_qvalue(Q, state_disc, next_state_disc, action, discount, learning_rate, reward, terminal):\n","    \"\"\"\n","\n","    Update Q values following the Q-learning update rule.\n","\n","    Be sure to handle the terminal state case.\n","\n","    Args:\n","        Q (np.array): The Q value matrix, here it is 3D for the two observation states and action states\n","        state_disc (np.array): the discretized version of the current observation state [position, velocity]\n","        next_state_disc (np.array): the discretized version of the next observation state [position, velocity]\n","        action (int): the chosen action\n","        discount (float): the discount factor, may be referred to as gamma\n","        learning_rate (float): the learning rate, may be referred to as alpha\n","        reward (float): the current (immediate) reward\n","        terminal (bool): flag for whether the state is terminal\n","\n","    Returns:\n","        Q, with the [state_disc[0], state_disc[1], action] entry updated.\n","    \"\"\"\n","    #### STUDENT CODE HERE ####\n","    if terminal == 0:\n","        Q[state_disc[0], state_disc[1], action] += learning_rate * (reward + discount * np.max(Q[next_state_disc[0], next_state_disc[1]]) - Q[state_disc[0], state_disc[1], action])\n","    else:\n","        Q[state_disc[0], state_disc[1], action] = reward\n","\n","    #### STUDENT CODE ENDS HERE ####\n","    return Q\n","\n","\n","def test_update_qvalue():\n","    Q = np.ones((3, 3, env.action_space.n))\n","    state_disc = (2, 2)\n","    next_state_disc = (2,1)\n","    action = 1\n","    discount = 0.9\n","    learning_rate = 0.01\n","    reward = 10\n","    terminal = False\n","    Q = update_qvalue(Q,state_disc,next_state_disc,action,discount,learning_rate, reward, terminal)\n","    if Q.tolist() != [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]], [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]], [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.099, 1.0]]]:\n","        print(\"Incorrect Q update\")\n","    else:\n","        print(\"Q update looks correct!\")\n","\n","test_update_qvalue()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":550,"status":"ok","timestamp":1701204522989,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"qnWW61oYRgeh","outputId":"81104485-4dae-4729-d9d7-d6f82698c0ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 5/5 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_update_Q_backend', answer = (grader_serialize(update_qvalue), env.action_space.n))"]},{"cell_type":"markdown","metadata":{"id":"5upsphRjXZnu"},"source":["###2.5 Main Q-learning Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NQ4KG3NYjHl"},"outputs":[],"source":["class ResizeObservation(gym.Wrapper):\n","    def __init__(self, env, shape):\n","        super(ResizeObservation, self).__init__(env)\n","        if isinstance(shape, int):\n","            shape = (shape, shape)\n","        assert all(x > 0 for x in shape), shape\n","        self.env = env\n","        self.shape = tuple(shape)\n","\n","    def render(self):\n","\n","        from PIL import Image\n","        obs = self.env.render(mode = 'rgb_array')\n","        im = Image.fromarray(np.uint8(obs))\n","        im = im.resize(self.shape)\n","        return np.asarray(im)"]},{"cell_type":"markdown","metadata":{"id":"acmiigM1XagE"},"source":["You have implemented all the untility functions for Q-learning. We've provided you the code for the main Q-learning loop, please carefully go through the next cell."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6BxOuusXcAT"},"outputs":[],"source":["def Qlearning(Q, discretization, env, learning_rate, discount, epsilon, decay_rate, max_episodes=5000):\n","    \"\"\"\n","\n","    The main Q-learning function, utilizing the functions implemented above.\n","\n","    \"\"\"\n","    reward_list = []\n","    position_list = []\n","    success_list = []\n","    success = 0 # count of number of successes reached\n","    frames = []\n","\n","    for i in range(max_episodes):\n","        # Initialize parameters\n","        done = False # indicates whether the episode is done\n","        terminal = False # indicates whether the episode is done AND the car has reached the flag (>=0.5 position)\n","        tot_reward = 0 # sum of total reward over a single\n","        state = env.reset() # initial environment state\n","        state_disc = discretize(state,discretization,env)\n","\n","        while done != True:\n","            # Determine next action\n","            action = choose_action(epsilon, Q, state_disc, env)\n","            # Get next_state, reward, and done using env.step(), see http://gym.openai.com/docs/#environments for reference\n","            if i==1 or i==(max_episodes-1):\n","               frames.append(env.render())\n","            next_state, reward, done, _ = env.step(action)\n","            # Discretize next state\n","            next_state_disc = discretize(next_state,discretization,env)\n","            # Update terminal\n","            terminal = done and next_state[0]>=0.5\n","            # Update Q\n","            Q = update_qvalue(Q,state_disc,next_state_disc,action,discount,learning_rate, reward, terminal)\n","            # Update tot_reward, state_disc, and success (if applicable)\n","            tot_reward += reward\n","            state_disc = next_state_disc\n","\n","            if terminal: success +=1\n","\n","        epsilon = update_epsilon(epsilon, decay_rate) #Update level of epsilon using update_epsilon()\n","\n","        # Track rewards\n","        reward_list.append(tot_reward)\n","        position_list.append(next_state[0])\n","        success_list.append(success/(i+1))\n","\n","        if (i+1) % 100 == 0:\n","            print('Episode: ', i+1, 'Average Reward over 100 Episodes: ',np.mean(reward_list))\n","            reward_list = []\n","\n","    env.close()\n","\n","    return Q, position_list, success_list, frames"]},{"cell_type":"markdown","metadata":{"id":"ImCUNOzKXh6s"},"source":["### 2.6 Define Params and Launch Q-learning [5 pts]"]},{"cell_type":"markdown","metadata":{"id":"Pf1d3MeCXijE"},"source":["This is the main function for launching the Q-learning. You can run this cell to train the Q-learning without modifying anything and results would be saved to `./expert_Q.npy`.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90363,"status":"ok","timestamp":1701205194244,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"aCUKXBQxXrgx","outputId":"8438b8f0-a84f-49cc-8b02-843b5acd1353"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode:  100 Average Reward over 100 Episodes:  -200.0\n","Episode:  200 Average Reward over 100 Episodes:  -199.57\n","Episode:  300 Average Reward over 100 Episodes:  -198.77\n","Episode:  400 Average Reward over 100 Episodes:  -197.23\n","Episode:  500 Average Reward over 100 Episodes:  -197.41\n","Episode:  600 Average Reward over 100 Episodes:  -189.45\n","Episode:  700 Average Reward over 100 Episodes:  -190.02\n","Episode:  800 Average Reward over 100 Episodes:  -181.63\n","Episode:  900 Average Reward over 100 Episodes:  -183.46\n","Episode:  1000 Average Reward over 100 Episodes:  -168.51\n","Episode:  1100 Average Reward over 100 Episodes:  -164.9\n","Episode:  1200 Average Reward over 100 Episodes:  -165.11\n","Episode:  1300 Average Reward over 100 Episodes:  -166.76\n","Episode:  1400 Average Reward over 100 Episodes:  -159.39\n","Episode:  1600 Average Reward over 100 Episodes:  -170.83\n","Episode:  1700 Average Reward over 100 Episodes:  -184.64\n","Episode:  1800 Average Reward over 100 Episodes:  -190.22\n","Episode:  1900 Average Reward over 100 Episodes:  -191.7\n","Episode:  2000 Average Reward over 100 Episodes:  -188.25\n","Episode:  2100 Average Reward over 100 Episodes:  -197.67\n","Episode:  2200 Average Reward over 100 Episodes:  -180.25\n","Episode:  2300 Average Reward over 100 Episodes:  -195.18\n","Episode:  2400 Average Reward over 100 Episodes:  -163.71\n","Episode:  2500 Average Reward over 100 Episodes:  -146.09\n","Episode:  2600 Average Reward over 100 Episodes:  -139.64\n","Episode:  2700 Average Reward over 100 Episodes:  -138.84\n","Episode:  2800 Average Reward over 100 Episodes:  -138.42\n","Episode:  2900 Average Reward over 100 Episodes:  -137.79\n","Episode:  3000 Average Reward over 100 Episodes:  -138.26\n","Episode:  3100 Average Reward over 100 Episodes:  -138.41\n","Episode:  3200 Average Reward over 100 Episodes:  -137.98\n","Episode:  3400 Average Reward over 100 Episodes:  -138.05\n","Episode:  3500 Average Reward over 100 Episodes:  -138.54\n","Episode:  3600 Average Reward over 100 Episodes:  -138.71\n","Episode:  3700 Average Reward over 100 Episodes:  -137.59\n","Episode:  3800 Average Reward over 100 Episodes:  -138.67\n","Episode:  3900 Average Reward over 100 Episodes:  -138.11\n","Episode:  4000 Average Reward over 100 Episodes:  -138.01\n","Episode:  4100 Average Reward over 100 Episodes:  -138.36\n","Episode:  4200 Average Reward over 100 Episodes:  -138.55\n","Episode:  4300 Average Reward over 100 Episodes:  -138.15\n","Episode:  4400 Average Reward over 100 Episodes:  -138.24\n","Episode:  4500 Average Reward over 100 Episodes:  -138.02\n","Episode:  4600 Average Reward over 100 Episodes:  -138.23\n","Episode:  4700 Average Reward over 100 Episodes:  -138.13\n","Episode:  4800 Average Reward over 100 Episodes:  -137.89\n","Episode:  4900 Average Reward over 100 Episodes:  -137.99\n","Episode:  5000 Average Reward over 100 Episodes:  -137.88\n","Looks like you're learning nicely!\n"]}],"source":["# Initialize Mountain Car Environment\n","env = gym.make('MountainCar-v0')\n","\n","env = ResizeObservation(env,100) #Resize observations\n","\n","env.seed(42)\n","np.random.seed(42)\n","env.reset()\n","\n","#### STUDENT CODE HERE ####\n","# Parameters\n","learning_rate = 0.3\n","discount = 0.95\n","epsilon = 0.9\n","decay_rate = 0.9\n","max_episodes = 5000\n","discretization = np.array([10,100])\n","\n","#### STUDENT CODE ENDS HERE ####\n","\n","\n","#InitQ\n","num_states = (env.observation_space.high - env.observation_space.low)*discretization\n","#Size of discretized state space\n","num_states = np.round(num_states, 0).astype(int) + 1\n","# Initialize Q table\n","Q = np.random.uniform(low = -1,\n","                      high = 1,\n","                      size = (num_states[0], num_states[1], env.action_space.n))\n","\n","\n","def test_Q_learning(successes):\n","    # Run Q Learning by calling your Qlearning() function\n","    if np.mean(successes[-1]) < 0.7:\n","        print(\"Your Q-learning algorithm isn't producing good enough results!\")\n","    else:\n","        print(\"Looks like you're learning nicely!\")\n","\n","Q, position, successes, frames = Qlearning(Q, discretization, env, learning_rate, discount, epsilon, decay_rate, max_episodes)\n","np.save('./expert_Q.npy',Q) #Save the expert\n","test_Q_learning(successes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1701205216595,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"LrHvrN6eYPAn","outputId":"842dc772-c9d9-4d88-a22f-9bd339877734"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct! You earned 5/5 points. You are a star!\n","\n","Your submission has been successfully recorded in the gradebook.\n"]}],"source":["# PennGrader Grading Cell\n","grader.grade(test_case_id = 'test_successes', answer = successes)"]},{"cell_type":"markdown","metadata":{"id":"HWwTx91qXtkW"},"source":["### 2.7 Visualization Results\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":927},"executionInfo":{"elapsed":1257,"status":"ok","timestamp":1701205233815,"user":{"displayName":"Hongkai Zhang","userId":"07987002827434176584"},"user_tz":480},"id":"IJNh1NcDXzIP","outputId":"47faa1df-e9b1-4e42-c2f2-71e9514e85c8"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","from PIL import Image\n","\n","plt.plot(successes)\n","plt.xlabel('Episode')\n","plt.ylabel('% of Episodes with Success')\n","plt.title('% Successes')\n","plt.show()\n","plt.close()\n","\n","p = pd.Series(position)\n","ma = p.rolling(3).mean()\n","plt.plot(p, alpha=0.8)\n","plt.plot(ma)\n","plt.xlabel('Episode')\n","plt.ylabel('Position')\n","plt.title('Car Final Position')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1udKCtUno7oJwzSfhw2MwG_gZNScK3p4z"},"id":"Lgf0_JQFXzxI","outputId":"90ee0fb3-4930-4afd-b75f-4ef45776e965"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#### Video plotting code #####################\n","deep_frames = []\n","for obs in frames:\n","  im = Image.fromarray(np.uint8(obs))\n","  im = im.resize((600,400))\n","  deep_frames.append(np.asarray(im))\n","\n","plt.figure(figsize=(deep_frames[0].shape[1] / 72.0, deep_frames[0].shape[0] / 72.0), dpi = 72)\n","patch = plt.imshow(deep_frames[0])\n","plt.axis('off')\n","animate = lambda i: patch.set_data(deep_frames[i])\n","ani = matplotlib.animation.FuncAnimation(plt.gcf(), animate, frames=len(deep_frames), interval = 50)\n","#HTML(ani.to_jshtml())\n","from IPython.display import display\n","display(HTML(ani.to_jshtml()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dw15abDcvBKK"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["oQCyLhELJ7LX","QnSMLJcrsYC0"],"provenance":[{"file_id":"17OIg1YjNYKG2_es88cpRX6vGpj6R_M3X","timestamp":1700353378098}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}